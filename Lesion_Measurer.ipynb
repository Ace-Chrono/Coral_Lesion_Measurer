{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ace-Chrono/Coral_Lesion_Measurer/blob/main/Lesion_Measurer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G-z1CWuBCEag",
      "metadata": {
        "id": "G-z1CWuBCEag"
      },
      "source": [
        "## Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573beb73-c95e-4c47-9d71-202619b25e13",
      "metadata": {
        "id": "573beb73-c95e-4c47-9d71-202619b25e13"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics #This is where we get the YOLO packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9789755c-6733-4125-b936-b162b6ab5621",
      "metadata": {
        "id": "9789755c-6733-4125-b936-b162b6ab5621",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/facebookresearch/sam2.git sam2_repo\n",
        "%cd sam2_repo\n",
        "!pip install -e . --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gTAgPny7zwtD",
      "metadata": {
        "id": "gTAgPny7zwtD"
      },
      "outputs": [],
      "source": [
        "!pip install ipympl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gWIWE-_oz1EP",
      "metadata": {
        "id": "gWIWE-_oz1EP"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XC4dApdp7MrT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC4dApdp7MrT",
        "outputId": "0bd6d4ca-c7dd-422e-d8c5-bf007365d3a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_ipython().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "itOjos5Yz3ss",
      "metadata": {
        "id": "itOjos5Yz3ss"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib widget\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Button, Output, VBox, HBox\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "import gc\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R3HbA_rRCmBx",
      "metadata": {
        "id": "R3HbA_rRCmBx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "Kx82OUj9Cpfx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx82OUj9Cpfx",
        "outputId": "f9a9e8bd-91a8-4360-86b8-ea30efa3b905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "2.6.0+cu124\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive/')\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.__version__)\n",
        "print(DEVICE) #Make sure to reload Anaconda if it prints out CPU even though it is the right PyTorch version\n",
        "lesion_bbox_model = YOLO(\"/content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/ML Models/YOLOV11_Lesion.pt\")\n",
        "ruler_bbox_model = YOLO(\"/content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/ML Models/YOLOV11_Ruler.pt\")\n",
        "sam_location = \"/content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/ML Models/sam2.1_hiera_large.pt\"\n",
        "sam_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "lesion_sam_model = SAM2ImagePredictor(build_sam2(sam_cfg, sam_location))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236f979c-0c30-4d49-84cf-e7d9885731e7",
      "metadata": {
        "id": "236f979c-0c30-4d49-84cf-e7d9885731e7"
      },
      "source": [
        "## YOLO and SAM Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c607b5a5-13a7-4921-b467-564d6869a42f",
      "metadata": {
        "id": "c607b5a5-13a7-4921-b467-564d6869a42f"
      },
      "outputs": [],
      "source": [
        "def open_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    height, width, channels = image_np.shape\n",
        "    return image, height, width\n",
        "\n",
        "def image_info(image_name):\n",
        "    date = None\n",
        "    repetition = None\n",
        "    id = None\n",
        "\n",
        "    parentheses_match = re.search(r'\\s*\\((\\d+)\\)$', image_name)\n",
        "    if parentheses_match:\n",
        "       repetition = int(parentheses_match.group(1))\n",
        "       image_name_clean = re.sub(r'\\s*\\(\\d+\\)$', '', image_name)\n",
        "    else:\n",
        "        image_name_clean = image_name\n",
        "\n",
        "    date_match = re.search(r'(\\d{4}_\\d{2}_\\d{2})', image_name_clean)\n",
        "    if date_match:\n",
        "        date_str = date_match.group(1)\n",
        "        date = date_str.replace('_', '-')\n",
        "\n",
        "    id_match = re.search(r'(LC[^_\\s]*)', image_name_clean)\n",
        "    if id_match:\n",
        "        id = id_match.group(1)\n",
        "\n",
        "    return id, date, repetition\n",
        "\n",
        "def get_conversion_ratio(image, image_name):\n",
        "    try:\n",
        "        results = ruler_bbox_model.predict(image, verbose=False)\n",
        "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
        "            bboxes = results[0].boxes\n",
        "            if len(bboxes.xyxy) > 0:\n",
        "                x_min, y_min, x_max, y_max = bboxes.xyxy[0].tolist()\n",
        "                width = x_max - x_min\n",
        "                height = y_max - y_min\n",
        "                conversion_ratio = max(width, height) / 30.5\n",
        "                print(f\"Ruler detected in {image_name}: {conversion_ratio:.2f} pixels/cm\")\n",
        "                return conversion_ratio\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ruler detection for {image_name}: {str(e)}\")\n",
        "    return None\n",
        "\n",
        "def run_yolo_lesion(image):\n",
        "    results = lesion_bbox_model.predict(image, verbose=False)\n",
        "    for result in results:\n",
        "        bboxes = result.boxes\n",
        "        bboxes = bboxes.xyxy.tolist()\n",
        "    return bboxes\n",
        "\n",
        "def run_sam(image, bboxes):\n",
        "    bboxes_np = []\n",
        "    for bbox in bboxes:\n",
        "        bbox_np = np.array(bbox)\n",
        "        bboxes_np.append(bbox_np)\n",
        "    input_boxes = np.array(bboxes_np).astype(np.float32)\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        lesion_sam_model.set_image(np.array(image))\n",
        "        masks, _, _ = lesion_sam_model.predict(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=input_boxes,               # shape: (N, 4)\n",
        "            multimask_output=False,\n",
        "        )\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa07d231-3497-4ab7-a437-685f983ee468",
      "metadata": {
        "id": "aa07d231-3497-4ab7-a437-685f983ee468"
      },
      "source": [
        "## Mask Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fAixuw23qgDS",
      "metadata": {
        "id": "fAixuw23qgDS"
      },
      "outputs": [],
      "source": [
        "def masks_to_polygons(masks):  # Creates polygons from a list of SAM masks\n",
        "    all_polygons = []\n",
        "\n",
        "    for mask in masks:\n",
        "        mask = np.squeeze(mask)  # Ensures (H, W)\n",
        "\n",
        "        if mask is None:\n",
        "            raise ValueError(f\"Mask {i} is None.\")\n",
        "        if mask.ndim != 2:\n",
        "            raise ValueError(f\"Mask {i} must be 2D after squeeze, got shape {mask.shape}\")\n",
        "        if mask.shape[0] == 0 or mask.shape[1] == 0:\n",
        "            raise ValueError(f\"Mask {i} has invalid shape {mask.shape}\")\n",
        "        if not np.any(mask):\n",
        "            continue  # Skip empty masks\n",
        "\n",
        "        # Convert mask to binary if it's not already\n",
        "        if mask.max() > 1:\n",
        "            _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        else:\n",
        "            binary_mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        polygons = []\n",
        "        for contour in contours:\n",
        "            # Simplify the contour to reduce the number of points\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Extract points and flatten the list\n",
        "            polygon = approx.reshape(-1, 2).tolist()\n",
        "            flat_polygon = [point for sublist in polygon for point in sublist]\n",
        "            polygons.append(flat_polygon)\n",
        "\n",
        "        all_polygons.append(polygons)\n",
        "\n",
        "    return all_polygons\n",
        "\n",
        "def get_perimeter(all_polygons, conversion_ratio):\n",
        "  perimeters = []\n",
        "  for polygon in all_polygons:\n",
        "    for points in polygon:\n",
        "      contour = np.array(points).reshape(-1, 1, 2)\n",
        "      perimeter = cv2.arcLength(contour, True)\n",
        "      perimeter_cm = perimeter / conversion_ratio\n",
        "      perimeter_um = perimeter_cm * 10_000\n",
        "      perimeters.append(perimeter_um)\n",
        "\n",
        "  return perimeters\n",
        "\n",
        "def get_areas_and_centers(masks, bboxes, conversion_ratio):\n",
        "    areas = []\n",
        "    centers = []\n",
        "    for mask in masks:\n",
        "        area = np.count_nonzero(mask)\n",
        "        area_um2 = area * ((1 / conversion_ratio)*10000)** 2\n",
        "        areas.append(area_um2)\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        center_x = (x_min + x_max) / 2\n",
        "        center_y = (y_min + y_max) / 2\n",
        "        centers.append((center_x, center_y))  # (x, y) format\n",
        "    return areas, centers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3846155b-7747-41b6-a8db-b2bffc849dab",
      "metadata": {
        "id": "3846155b-7747-41b6-a8db-b2bffc849dab"
      },
      "source": [
        "## Outputting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7909165-7a6d-4054-903e-ef5ad7417a5d",
      "metadata": {
        "id": "b7909165-7a6d-4054-903e-ef5ad7417a5d"
      },
      "outputs": [],
      "source": [
        "def output_image_cv(image, bboxes, masks, segmentations, areas, centers, image_output_path):\n",
        "    # Convert PIL Image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)\n",
        "\n",
        "    img = image.copy()\n",
        "\n",
        "    # Convert RGB to BGR for OpenCV display\n",
        "    if img.shape[-1] == 3:  # Check for color image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # Draw bounding boxes (green)\n",
        "    for box in bboxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Draw SAM masks (semi-transparent blue overlays)\n",
        "    for mask in masks:\n",
        "        if mask.dtype != np.uint8:\n",
        "            mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "        if len(mask.shape) == 3:\n",
        "            mask = mask.squeeze()\n",
        "\n",
        "        # Create colored overlay\n",
        "        color_mask = np.zeros_like(img, dtype=np.uint8)\n",
        "        color_mask[:, :, 0] = 255  # Blue in BGR\n",
        "        alpha = 0.2\n",
        "\n",
        "        # Create 3-channel mask and blend it\n",
        "        mask_3ch = np.stack([mask]*3, axis=-1)\n",
        "        img = np.where(mask_3ch, (1 - alpha) * img + alpha * color_mask, img).astype(np.uint8)\n",
        "\n",
        "    # Draw segmentation polygons (red outlines)\n",
        "    for polygons in segmentations:\n",
        "        formatted_polygons = [np.array(polygon, dtype=np.int32).reshape(-1, 2) for polygon in polygons]\n",
        "        for polygon in formatted_polygons:\n",
        "            cv2.polylines(img, [polygon], isClosed=True, color=(0, 0, 255), thickness=2)\n",
        "\n",
        "    # Draw area annotations (white text with black background)\n",
        "    for i, (area, center) in enumerate(zip(areas, centers)):\n",
        "        x, y = map(int, center)\n",
        "        text = f\"{area:.2f} um^2\"\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.6\n",
        "        thickness = 1\n",
        "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "        text_w, text_h = text_size\n",
        "\n",
        "        # Draw background rectangle\n",
        "        cv2.rectangle(img, (x, y - text_h), (x + text_w, y), (0, 0, 0), -1)\n",
        "        # Put text\n",
        "        cv2.putText(img, text, (x, y - 2), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Save image\n",
        "    cv2.imwrite(image_output_path, img)\n",
        "\n",
        "def output_csv(folder_name, image_name, lesion_count, conversion_ratio, areas, perimeters, csv_output_path):\n",
        "\n",
        "    for i in range(len(areas)):\n",
        "        areas[i] = float(areas[i])\n",
        "        perimeters[i] = float(perimeters[i])\n",
        "\n",
        "    new_row = {\n",
        "        \"Folder\": folder_name,\n",
        "        \"Image Name\": image_name,\n",
        "        \"# Lesions\": lesion_count,\n",
        "        \"Pixels Per um\": conversion_ratio,\n",
        "        \"um^2\": areas,\n",
        "        \"Perimeters\": perimeters\n",
        "        }\n",
        "    new_row_df = pd.DataFrame([new_row], columns=csv_columns)\n",
        "    new_row_df.to_csv(csv_output_path, mode='a', header=not os.path.exists(csv_output_path), index=False)\n",
        "\n",
        "def get_metadata(index, image_name, height, width, bboxes, segmentations):\n",
        "    image_info = {\n",
        "        \"id\": index,\n",
        "        \"license\": 1,\n",
        "        \"file_name\": image_name,\n",
        "        \"height\": height,\n",
        "        \"width\": width,\n",
        "        \"date_captured\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "    annotations = []\n",
        "    for annotation_id, (bbox, segmentation) in enumerate(zip(bboxes, segmentations)):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        width_box = x_max - x_min\n",
        "        height_box = y_max - y_min\n",
        "        area = width_box * height_box\n",
        "\n",
        "        annotation_info = {\n",
        "            \"id\": index * 1000 + annotation_id,  # ensures uniqueness\n",
        "            \"image_id\": index,\n",
        "            \"category_id\": 1,\n",
        "            \"bbox\": [x_min, y_min, width_box, height_box],\n",
        "            \"area\": area,\n",
        "            \"segmentation\": segmentation,\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "        annotations.append(annotation_info)\n",
        "    return image_info, annotations\n",
        "\n",
        "def output_coco_json(image_info_list, annotations_list, output_path):\n",
        "    coco_dict = {\n",
        "        \"info\": {\n",
        "            \"description\": \"Coral Dataset\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2025,\n",
        "            \"contributor\": \"Richard Zhao\",\n",
        "            \"date_created\": datetime.datetime.now().isoformat()\n",
        "        },\n",
        "        \"licenses\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "            }\n",
        "        ],\n",
        "        \"images\": image_info_list,\n",
        "        \"annotations\": annotations_list,\n",
        "        \"categories\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"coral lesion\",\n",
        "                \"supercategory\": \"marine_life\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save to JSON file\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(coco_dict, f, indent=4)\n",
        "\n",
        "\n",
        "def append_row_to_excel(file_path, new_row_dict):\n",
        "    if os.path.exists(file_path):\n",
        "        df_existing = pd.read_excel(file_path)\n",
        "        # Check if date already exists\n",
        "        if new_row_dict['Date'] in df_existing['Date'].values:\n",
        "            print(f\"Skipping duplicate date {new_row_dict['Date']} in {file_path}\")\n",
        "            return\n",
        "        df_existing = pd.concat([df_existing, pd.DataFrame([new_row_dict])], ignore_index=True)\n",
        "        df_existing = df_existing.sort_values(by='Date')\n",
        "        df_existing.to_excel(file_path, index=False)\n",
        "    else:\n",
        "        pd.DataFrame([new_row_dict]).to_excel(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IZ31PF-I0eeH",
      "metadata": {
        "id": "IZ31PF-I0eeH"
      },
      "source": [
        "##Manual Conversion Ratio GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9cjBzzBh0g9g",
      "metadata": {
        "id": "9cjBzzBh0g9g"
      },
      "outputs": [],
      "source": [
        "class ClickCollector:\n",
        "    def __init__(self, image, image_name=\"Image\", on_done=None):\n",
        "        self.image = image\n",
        "        self.image_name = image_name\n",
        "        self.on_done = on_done\n",
        "        self.coords = []\n",
        "        self.line = None\n",
        "        self.dots = []\n",
        "        self.click_mode = False\n",
        "\n",
        "        self.out = Output()\n",
        "\n",
        "        # Setup plot\n",
        "        with self.out:\n",
        "            self.fig, self.ax = plt.subplots(figsize=(8,6))\n",
        "            self.ax.imshow(self.image)\n",
        "            self.ax.set_title(f\"{self.image_name}\")\n",
        "            self.cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
        "            plt.show()\n",
        "\n",
        "        # Buttons\n",
        "        self.click_button = Button(description=\"Enable Click Mode\", button_style='primary')\n",
        "        self.click_button.on_click(self.toggle_click_mode)\n",
        "\n",
        "        self.clear_button = Button(description=\"Clear\", button_style='danger')\n",
        "        self.clear_button.on_click(self.clear)\n",
        "\n",
        "        self.finish_button = Button(description=\"Finish\", button_style='success')\n",
        "        self.finish_button.on_click(self.finish)\n",
        "\n",
        "        # Distance input & submit button, hidden initially\n",
        "        self.dist_input = widgets.FloatText(description=\"Real distance (cm):\")\n",
        "        self.dist_submit = widgets.Button(description=\"Submit distance\")\n",
        "        self.dist_submit.on_click(self.submit_distance)\n",
        "        self.dist_input.layout.display = 'none'\n",
        "        self.dist_submit.layout.display = 'none'\n",
        "\n",
        "        display(VBox([\n",
        "            self.out,\n",
        "            HBox([self.click_button, self.clear_button, self.finish_button]),\n",
        "            VBox([self.dist_input, self.dist_submit])\n",
        "        ]))\n",
        "\n",
        "    def toggle_click_mode(self, b):\n",
        "        self.click_mode = not self.click_mode\n",
        "        if self.click_mode:\n",
        "            self.click_button.description = \"Click Mode: ON (Click Image)\"\n",
        "            self.click_button.button_style = 'warning'\n",
        "            print(\"üñ±Ô∏è Click mode enabled: Click two points.\")\n",
        "        else:\n",
        "            self.click_button.description = \"Click Mode: OFF\"\n",
        "            self.click_button.button_style = 'primary'\n",
        "            print(\"‚úã Click mode disabled: Use zoom/pan tools.\")\n",
        "\n",
        "    def onclick(self, event):\n",
        "        if not self.click_mode or event.inaxes != self.ax:\n",
        "            return\n",
        "        x, y = event.xdata, event.ydata\n",
        "        print(f\"üìç Clicked at ({x:.1f}, {y:.1f})\")\n",
        "        self.coords.append((x, y))\n",
        "        self.draw_dot(x, y)\n",
        "        if len(self.coords) == 2:\n",
        "            self.draw_line()\n",
        "            self.toggle_click_mode(None)\n",
        "\n",
        "    def draw_dot(self, x, y):\n",
        "        dot = self.ax.plot(x, y, 'ro', markersize=6)[0]\n",
        "        self.dots.append(dot)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def draw_line(self):\n",
        "        x_vals = [self.coords[0][0], self.coords[1][0]]\n",
        "        y_vals = [self.coords[0][1], self.coords[1][1]]\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "        self.line, = self.ax.plot(x_vals, y_vals, 'r-', linewidth=2)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def clear(self, b):\n",
        "        # Clear all dots\n",
        "        for dot in self.dots:\n",
        "            dot.remove()\n",
        "        self.dots = []\n",
        "\n",
        "        # Clear line\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "            self.line = None\n",
        "\n",
        "        self.coords = []\n",
        "        self.fig.canvas.draw()\n",
        "        print(\"üßπ Cleared all points and lines.\")\n",
        "\n",
        "    def finish(self, b):\n",
        "        if len(self.coords) != 2:\n",
        "            with self.out:\n",
        "                print(\"Please click exactly 2 points before finishing.\")\n",
        "            return\n",
        "        with self.out:\n",
        "            print(f\"‚úÖ Line set from {self.coords[0]} to {self.coords[1]}\")\n",
        "            print(\"Please enter the real-world distance (cm) below:\")\n",
        "        # Show distance input widgets\n",
        "        self.dist_input.layout.display = None\n",
        "        self.dist_submit.layout.display = None\n",
        "\n",
        "    def submit_distance(self, b):\n",
        "        dist = self.dist_input.value\n",
        "        if dist <= 0:\n",
        "            with self.out:\n",
        "                print(\"Distance must be positive.\")\n",
        "            return\n",
        "        pixel_dist = np.linalg.norm(np.array(self.coords[0]) - np.array(self.coords[1]))\n",
        "        ratio = pixel_dist / dist\n",
        "        with self.out:\n",
        "            print(f\"‚û°Ô∏è Pixel distance: {pixel_dist:.2f}\")\n",
        "            print(f\"‚û°Ô∏è Real distance: {dist:.2f} cm\")\n",
        "            print(f\"‚û°Ô∏è Conversion ratio: {ratio:.2f} pixels/cm\")\n",
        "        if self.on_done:\n",
        "            self.on_done(ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb0e46b-8952-483a-95a2-f4ac63032220",
      "metadata": {
        "id": "cfb0e46b-8952-483a-95a2-f4ac63032220"
      },
      "source": [
        "## Define Path Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11fab7a8-9a13-4f73-8a76-79f38ebb9402",
      "metadata": {
        "id": "11fab7a8-9a13-4f73-8a76-79f38ebb9402"
      },
      "outputs": [],
      "source": [
        "image_input_root = \"/content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/Input/\"\n",
        "\n",
        "image_input_path = [\n",
        "    os.path.join(root, d)\n",
        "    for root, dirs, _ in os.walk(image_input_root)\n",
        "    for d in dirs\n",
        "]\n",
        "image_input_path.append(image_input_root)\n",
        "\n",
        "image_output_path = \"/content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/Output/\"\n",
        "csv_output_path = image_output_path + \"/coral_areas_output.csv\"\n",
        "csv_columns = [\"Folder\", \"Image Name\", \"# Lesions\", \"Pixels Per um\", \"um^2\", \"Perimeters\"]\n",
        "\n",
        "areas_folder = os.path.join(image_output_path, \"areas\")\n",
        "perimeters_folder = os.path.join(image_output_path, \"perimeters\")\n",
        "os.makedirs(areas_folder, exist_ok=True)\n",
        "os.makedirs(perimeters_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7",
      "metadata": {
        "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7"
      },
      "source": [
        "## Run Measurer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "1db6ab08f88f4e1d9ce0a3888cf827d8",
            "71ac6a5f6af74bd09909aacb51b2fdad"
          ]
        },
        "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f",
        "outputId": "7a5a840e-3a60-48c3-d46f-de3cbed3fa7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruler detected in RRC_S1_ECA_LC-041_a_2021_05_28 (1): 66.60 pixels/mm\n",
            "Skipping duplicate date 2021-05-28 in /content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/Output/areas/LC-041_areas.xlsx\n",
            "Skipping duplicate date 2021-05-28 in /content/gdrive/MyDrive/Coral Lesion Research/Prototype Code/Output/perimeters/LC-041_perimeters.xlsx\n",
            "peak memory: 3682.16 MiB, increment: 653.26 MiB\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1db6ab08f88f4e1d9ce0a3888cf827d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pending_conversion = {}\n",
        "\n",
        "for index, folder in enumerate(image_input_path):\n",
        "    image_metadata_list = []\n",
        "    annotation_metadata_list = []\n",
        "    folder_name = os.path.basename(folder.rstrip('/'))\n",
        "    json_output_path = os.path.join(image_output_path, \"_annotations.coco.json\")\n",
        "    image_index = 0\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith('.JPG'):\n",
        "            old_image_path = os.path.join(folder, file)\n",
        "            image_name, _ = os.path.splitext(file)\n",
        "            image_name_png = image_name + \".png\"\n",
        "            new_image_path = os.path.join(image_output_path, image_name_png)\n",
        "            image, height, width = open_image(old_image_path)\n",
        "\n",
        "            conversion_ratio = get_conversion_ratio(image, image_name)\n",
        "            if conversion_ratio is None:\n",
        "                pending_conversion[image_name] = (image, height, width, old_image_path)\n",
        "                continue\n",
        "\n",
        "            bboxes_lesion = run_yolo_lesion(image)\n",
        "            masks_lesion = run_sam(image, bboxes_lesion)\n",
        "            segmentations = masks_to_polygons(masks_lesion)\n",
        "            perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "            areas, centers = get_areas_and_centers(masks_lesion, bboxes_lesion, conversion_ratio)\n",
        "            id, date, repetition = image_info(image_name)\n",
        "\n",
        "            area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "            perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "            area_row = {'Date': date}\n",
        "            for i, a in enumerate(areas):\n",
        "                area_row[f'Area {i+1}'] = a\n",
        "            perim_row = {'Date': date}\n",
        "            for i, p in enumerate(perimeters):\n",
        "                perim_row[f'Perimeter {i+1}'] = p\n",
        "            append_row_to_excel(area_file, area_row)\n",
        "            append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "            output_image_cv(image, bboxes_lesion, masks_lesion, segmentations, areas, centers, new_image_path)\n",
        "            output_csv(folder_name, image_name_png, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "            image_metadata, annotation_metadata = get_metadata(image_index, image_name_png, height, width, bboxes_lesion, segmentations)\n",
        "            image_metadata_list.append(image_metadata)\n",
        "            annotation_metadata_list.append(annotation_metadata)\n",
        "\n",
        "            image_index += 1\n",
        "            del image, bboxes_lesion, masks_lesion, segmentations, areas, centers\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if image_metadata_list and annotation_metadata_list:\n",
        "        output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "\n",
        "resolved_ratios = {}\n",
        "\n",
        "pending_items = list(pending_conversion.items())\n",
        "current_idx = 0\n",
        "\n",
        "main_output = widgets.Output()\n",
        "display(main_output)\n",
        "\n",
        "manual_output_path = image_output_path + \"/manual_conversion\"\n",
        "os.makedirs(manual_output_path, exist_ok=True)\n",
        "image_metadata_list = []\n",
        "annotation_metadata_list = []\n",
        "folder_name = os.path.basename(folder.rstrip('/'))\n",
        "json_output_path = os.path.join(manual_output_path, \"_annotations.coco.json\")\n",
        "# image_index = 0\n",
        "\n",
        "def process_next():\n",
        "    global current_idx\n",
        "    if current_idx >= len(pending_items):\n",
        "        with main_output:\n",
        "            clear_output()\n",
        "            print(\"All ratios collected. Now running analysis...\\n\")\n",
        "        run_analysis()\n",
        "        return\n",
        "\n",
        "    image_name, (image, height, width, old_image_path) = pending_items[current_idx]\n",
        "    current_idx += 1\n",
        "\n",
        "    def handle_ratio(ratio):\n",
        "        resolved_ratios[image_name] = ratio\n",
        "        process_next()\n",
        "\n",
        "    with main_output:\n",
        "        clear_output(wait=True)\n",
        "        ClickCollector(image, image_name, on_done=handle_ratio)\n",
        "\n",
        "def run_analysis():\n",
        "    image_index = 0\n",
        "    for image_name, conversion_ratio in resolved_ratios.items():\n",
        "        if conversion_ratio is None:\n",
        "            print(f\"Skipping image {image_name} due to missing conversion ratio.\")\n",
        "            continue\n",
        "\n",
        "        image, height, width, old_image_path = pending_conversion[image_name]\n",
        "        image_name_png = image_name + \".png\"\n",
        "        new_image_path = os.path.join(manual_output_path, image_name_png)\n",
        "\n",
        "        bboxes_lesion = run_yolo_lesion(image)\n",
        "        masks_lesion = run_sam(image, bboxes_lesion)\n",
        "        segmentations = masks_to_polygons(masks_lesion)\n",
        "        perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "        areas, centers = get_areas_and_centers(masks_lesion, bboxes_lesion, conversion_ratio)\n",
        "        id, date, repetition = image_info(image_name)\n",
        "\n",
        "        # Excel\n",
        "        area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "        perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "        area_row = {'Date': date}\n",
        "        for i, a in enumerate(areas):\n",
        "            area_row[f'Area {i+1}'] = a\n",
        "        perim_row = {'Date': date}\n",
        "        for i, p in enumerate(perimeters):\n",
        "            perim_row[f'Perimeter {i+1}'] = p\n",
        "        append_row_to_excel(area_file, area_row)\n",
        "        append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "        # Output image + CSV\n",
        "        output_image_cv(image, bboxes_lesion, masks_lesion, segmentations, areas, centers, new_image_path)\n",
        "        output_csv(\"manual_conversion\", image_name_png, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "        image_metadata, annotation_metadata = get_metadata(image_index, image_name_png, height, width, bboxes_lesion, segmentations)\n",
        "        image_metadata_list.append(image_metadata)\n",
        "        annotation_metadata_list.append(annotation_metadata)\n",
        "\n",
        "        image_index += 1\n",
        "        del image, bboxes_lesion, masks_lesion, segmentations, areas, centers\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if image_metadata_list and annotation_metadata_list:\n",
        "        output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "\n",
        "if pending_conversion:\n",
        "    process_next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hrAScCEZ_qzu",
      "metadata": {
        "id": "hrAScCEZ_qzu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1db6ab08f88f4e1d9ce0a3888cf827d8": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_71ac6a5f6af74bd09909aacb51b2fdad",
            "msg_id": "",
            "outputs": []
          }
        },
        "71ac6a5f6af74bd09909aacb51b2fdad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
