{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ace-Chrono/Coral_Lesion_Measurer/blob/main/Lesion_Measurer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3Y68KXcf6KIc",
      "metadata": {
        "id": "3Y68KXcf6KIc"
      },
      "source": [
        "## Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MPYowhDr5V6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPYowhDr5V6d",
        "outputId": "4cf53894-8eae-4d6c-cef5-7b1c67d21e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n",
            "Cloning into 'sam2_repo'...\n",
            "remote: Enumerating objects: 1070, done.\u001b[K\n",
            "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1070/1070), 128.11 MiB | 12.04 MiB/s, done.\n",
            "Resolving deltas: 100% (381/381), done.\n",
            "/content/sam2_repo\n",
            "Obtaining file:///content/sam2_repo\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.3.0)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (25.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.14.1)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: SAM-2, iopath\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=SAM_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13744 sha256=f55aaf39132daa999587b95fbb66e2d87bec1fc2a2e0b41b5638e10d1dfb85ce\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-o_x6hny7/wheels/a3/2c/d5/dfadcadd6d3d572079cd6218a4b7ec6885fa349c5ba7335b4b\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=57ec56707518eb80fbbd8d9992c4ecd67861ed92ccfa4960832ce53767173a70\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 iopath\n",
            "Installing collected packages: portalocker, iopath, hydra-core, SAM-2\n",
            "Successfully installed SAM-2-1.0 hydra-core-1.3.2 iopath-0.1.10 portalocker-3.2.0\n",
            "Collecting ipympl\n",
            "  Downloading ipympl-0.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from ipympl) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from ipympl) (11.3.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.11/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython<10->ipympl)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.25.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Downloading ipympl-0.9.7-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, ipympl\n",
            "Successfully installed ipympl-0.9.7 jedi-0.19.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!git clone https://github.com/facebookresearch/sam2.git sam2_repo\n",
        "%cd sam2_repo\n",
        "!pip install -e . --no-build-isolation\n",
        "!pip install ipympl\n",
        "get_ipython().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gWIWE-_oz1EP",
      "metadata": {
        "id": "gWIWE-_oz1EP"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "itOjos5Yz3ss",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itOjos5Yz3ss",
        "outputId": "c34fdf1e-41a7-4ed7-8227-4326dcf5b508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mounted at /content/gdrive/\n",
            "2.6.0+cu124\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, files\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "%matplotlib widget\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Button, Output, VBox, HBox, Label\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "drive.mount('/content/gdrive/')\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.__version__)\n",
        "print(DEVICE)\n",
        "pvc_bbox_model = YOLO(\"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/ML Models/YOLOV11_PVC.pt\")\n",
        "lesion_bbox_model = YOLO(\"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/ML Models/YOLOV11_Lesion.pt\")\n",
        "ruler_bbox_model = YOLO(\"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/ML Models/YOLOV11_Ruler.pt\")\n",
        "sam_location = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/ML Models/sam2.1_hiera_large.pt\"\n",
        "sam_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "lesion_sam_model = SAM2ImagePredictor(build_sam2(sam_cfg, sam_location))\n",
        "\n",
        "def open_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    height, width, channels = image_np.shape\n",
        "    return image, height, width\n",
        "\n",
        "def image_info(image_name):\n",
        "    date = None\n",
        "    repetition = None\n",
        "    coral_id = None\n",
        "\n",
        "    # Extract and remove repetition (e.g., (2)) at the end\n",
        "    repetition_match = re.search(r'\\((\\d+)\\)\\s*$', image_name)\n",
        "    if repetition_match:\n",
        "        repetition = int(repetition_match.group(1))\n",
        "        image_name = re.sub(r'\\s*\\(\\d+\\)\\s*$', '', image_name)\n",
        "\n",
        "    # Match date with separators: _, ., or space (e.g., 2023_06_05, 2023.06.05, 2023 06 05)\n",
        "    date_match = re.search(r'(\\d{4})[_.\\s](\\d{2})[_.\\s](\\d{2})', image_name)\n",
        "    if date_match:\n",
        "        date = f\"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}\"\n",
        "\n",
        "        # Get the part before the date\n",
        "        pre_date = image_name[:date_match.start()].rstrip(' _.')\n",
        "\n",
        "        # Extract last coral ID-like token (e.g., LC_007_ab → LC_007)\n",
        "        coral_id_match = re.search(r'([A-Z]+[_-]\\d+)', pre_date)\n",
        "        if coral_id_match:\n",
        "            coral_id = coral_id_match.group(1)\n",
        "\n",
        "    return coral_id, date, repetition\n",
        "\n",
        "def get_conversion_ratio(image, image_name):\n",
        "    try:\n",
        "        results = ruler_bbox_model.predict(image, verbose=False)\n",
        "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
        "            bboxes = results[0].boxes\n",
        "            if len(bboxes.xyxy) > 0:\n",
        "                x_min, y_min, x_max, y_max = bboxes.xyxy[0].tolist()\n",
        "                width = x_max - x_min\n",
        "                height = y_max - y_min\n",
        "                conversion_ratio = max(width, height) / 30.5\n",
        "                return conversion_ratio, bboxes.xyxy[0].tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ruler detection for {image_name}: {str(e)}\")\n",
        "\n",
        "    # No detection\n",
        "    return None, None\n",
        "\n",
        "def get_pvc_ratio(image, image_name):\n",
        "    try:\n",
        "        results = pvc_bbox_model.predict(image, verbose=False)\n",
        "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
        "            bboxes = results[0].boxes\n",
        "            if len(bboxes.xyxy) > 0:\n",
        "                x_min, y_min, x_max, y_max = bboxes.xyxy[0].tolist()\n",
        "                width = x_max - x_min\n",
        "                height = y_max - y_min\n",
        "                conversion_ratio = max(width, height) / 7.15\n",
        "                return conversion_ratio, bboxes.xyxy[0].tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in PVC detection for {image_name}: {str(e)}\")\n",
        "    return None, None\n",
        "\n",
        "def run_yolo_lesion(image):\n",
        "    results = lesion_bbox_model.predict(image, verbose=False)\n",
        "    for result in results:\n",
        "        bboxes = result.boxes\n",
        "        bboxes = bboxes.xyxy.tolist()\n",
        "    return bboxes\n",
        "\n",
        "def run_sam(image, bboxes):\n",
        "    bboxes_np = []\n",
        "    for bbox in bboxes:\n",
        "        bbox_np = np.array(bbox)\n",
        "        bboxes_np.append(bbox_np)\n",
        "    input_boxes = np.array(bboxes_np).astype(np.float32)\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        lesion_sam_model.set_image(np.array(image))\n",
        "        masks, _, _ = lesion_sam_model.predict(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=input_boxes,               # shape: (N, 4)\n",
        "            multimask_output=False,\n",
        "        )\n",
        "    return masks\n",
        "\n",
        "def overlap_filtering(bboxes, masks, iou_thresh=0.8):\n",
        "    keep = [True] * len(masks)\n",
        "\n",
        "    for i in range(len(masks)):\n",
        "        for j in range(len(masks)):\n",
        "            if i == j or not keep[j]:\n",
        "                continue\n",
        "\n",
        "            # Extract the (H, W) masks from (1, H, W)\n",
        "            mask_i = masks[i][0].astype(np.uint8)\n",
        "            mask_j = masks[j][0].astype(np.uint8)\n",
        "\n",
        "            intersection = np.logical_and(mask_i, mask_j).sum()\n",
        "            area_j = mask_j.sum()\n",
        "\n",
        "            if area_j == 0:\n",
        "                continue\n",
        "\n",
        "            overlap_ratio = intersection / area_j\n",
        "\n",
        "            # Remove smaller mask if it's mostly inside the larger one\n",
        "            if overlap_ratio > iou_thresh and mask_i.sum() > mask_j.sum():\n",
        "                keep[j] = False\n",
        "\n",
        "    filtered = [(bbox, mask) for k, (bbox, mask) in enumerate(zip(bboxes, masks)) if keep[k]]\n",
        "    return filtered\n",
        "\n",
        "def masks_to_polygons(masks):  # Creates polygons from a list of SAM masks\n",
        "    all_polygons = []\n",
        "\n",
        "    for mask in masks:\n",
        "        mask = np.squeeze(mask)  # Ensures (H, W)\n",
        "\n",
        "        if mask is None:\n",
        "            raise ValueError(f\"Mask {i} is None.\")\n",
        "        if mask.ndim != 2:\n",
        "            raise ValueError(f\"Mask {i} must be 2D after squeeze, got shape {mask.shape}\")\n",
        "        if mask.shape[0] == 0 or mask.shape[1] == 0:\n",
        "            raise ValueError(f\"Mask {i} has invalid shape {mask.shape}\")\n",
        "        if not np.any(mask):\n",
        "            continue  # Skip empty masks\n",
        "\n",
        "        # Convert mask to binary if it's not already\n",
        "        if mask.max() > 1:\n",
        "            _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        else:\n",
        "            binary_mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        polygons = []\n",
        "        for contour in contours:\n",
        "            # Simplify the contour to reduce the number of points\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Extract points and flatten the list\n",
        "            polygon = approx.reshape(-1, 2).tolist()\n",
        "            flat_polygon = [point for sublist in polygon for point in sublist]\n",
        "            polygons.append(flat_polygon)\n",
        "\n",
        "        all_polygons.append(polygons)\n",
        "\n",
        "    return all_polygons\n",
        "\n",
        "def get_perimeter(all_polygons, conversion_ratio):\n",
        "    perimeters = []\n",
        "\n",
        "    for polygon in all_polygons:  # each object’s list of polygons\n",
        "        total_perimeter_px = 0\n",
        "\n",
        "        for points in polygon:\n",
        "            if len(points) < 6:\n",
        "                continue  # must have at least 3 points\n",
        "\n",
        "            try:\n",
        "                # Force correct shape and dtype (OpenCV requires float32 or int32)\n",
        "                contour = np.array(points, dtype=np.float32).reshape(-1, 1, 2)\n",
        "                perimeter = cv2.arcLength(contour, True)\n",
        "                perimeter_cm = perimeter / conversion_ratio\n",
        "                total_perimeter_px += perimeter_cm\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        perimeter_um = perimeter_cm * 10_000\n",
        "        perimeters.append(perimeter_um)\n",
        "\n",
        "    return perimeters\n",
        "\n",
        "def get_perimeter_list(all_polygons):\n",
        "    all_perimeters = []\n",
        "\n",
        "    for polygon in all_polygons:\n",
        "        perimeter_points = []\n",
        "        for points in polygon:\n",
        "            if len(points) < 6:\n",
        "              continue\n",
        "            for i in range(0, len(points), 2):\n",
        "                perimeter_points.append(points[i:i+2])\n",
        "        all_perimeters.append(perimeter_points)\n",
        "\n",
        "    return all_perimeters\n",
        "\n",
        "def get_areas_and_centers(masks, bboxes, conversion_ratio):\n",
        "    areas = []\n",
        "    centers = []\n",
        "    for mask in masks:\n",
        "        area = np.count_nonzero(mask)\n",
        "        area_um2 = area * ((1 / conversion_ratio)*10000)** 2\n",
        "        areas.append(area_um2)\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        center_x = (x_min + x_max) / 2\n",
        "        center_y = (y_min + y_max) / 2\n",
        "        centers.append((center_x, center_y))  # (x, y) format\n",
        "    return areas, centers\n",
        "\n",
        "def get_areas_and_centers_from_polygons(polygons_per_obj, bboxes, conversion_ratio):\n",
        "    areas = []\n",
        "    centers = []\n",
        "\n",
        "    for poly_list in polygons_per_obj:  # poly_list = list of polygons for one object\n",
        "        total_area_px = 0\n",
        "\n",
        "        for poly in poly_list:\n",
        "            if not poly:\n",
        "                continue\n",
        "            coords = np.array(poly).reshape(-1, 2)\n",
        "            x = coords[:, 0]\n",
        "            y = coords[:, 1]\n",
        "            area_px = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
        "            total_area_px += area_px\n",
        "\n",
        "        area_um2 = total_area_px * ((1 / conversion_ratio) * 10000) ** 2\n",
        "        areas.append(area_um2)\n",
        "\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        center_x = (x_min + x_max) / 2\n",
        "        center_y = (y_min + y_max) / 2\n",
        "        centers.append((center_x, center_y))\n",
        "\n",
        "    return areas, centers\n",
        "\n",
        "def output_image_cv(image, conversion_ratio, conversion_bbox, bboxes, masks, segmentations, areas, centers, image_output_path):\n",
        "    # Convert PIL Image to NumPy array if necessary\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)\n",
        "\n",
        "    img = image.copy()\n",
        "\n",
        "    # Convert RGB to BGR for OpenCV display\n",
        "    if img.shape[-1] == 3:  # Check for color image\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    if conversion_ratio:\n",
        "        ratio_text = f\"Conversion Ratio: {conversion_ratio:.0f} pixels/cm\"  # Format as needed\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 1\n",
        "        thickness = 1\n",
        "        text_color = (255, 255, 255)\n",
        "        text_size, _ = cv2.getTextSize(ratio_text, font, font_scale, thickness)\n",
        "        text_w, text_h = text_size\n",
        "        if conversion_bbox:\n",
        "            x1, y1, x2, y2 = map(int, conversion_bbox)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            x = (x1 + x2) // 2\n",
        "            y = (y1 + y2) // 2\n",
        "            cv2.rectangle(img, (x, y - text_h), (x + text_w, y), (0, 0, 0), -1)\n",
        "            cv2.putText(img, ratio_text, (x, y - 2), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
        "        else:\n",
        "            x, y = 10, 20\n",
        "            cv2.rectangle(img, (x, y - text_h), (x + text_w, y), (0, 0, 0), -1)\n",
        "            cv2.putText(img, ratio_text, (x, y - 2), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "    for box in bboxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    if masks:\n",
        "        for mask in masks:\n",
        "            if mask.dtype != np.uint8:\n",
        "                mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "            if len(mask.shape) == 3:\n",
        "                mask = mask.squeeze()\n",
        "\n",
        "            # Create colored overlay\n",
        "            color_mask = np.zeros_like(img, dtype=np.uint8)\n",
        "            color_mask[:, :, 0] = 255  # Blue in BGR\n",
        "            alpha = 0.2\n",
        "\n",
        "            # Create 3-channel mask and blend it\n",
        "            mask_3ch = np.stack([mask]*3, axis=-1)\n",
        "            img = np.where(mask_3ch, (1 - alpha) * img + alpha * color_mask, img).astype(np.uint8)\n",
        "\n",
        "\n",
        "    # Draw segmentation polygons (red outlines)\n",
        "    for polygons in segmentations:\n",
        "        formatted_polygons = [np.array(polygon, dtype=np.int32).reshape(-1, 2) for polygon in polygons]\n",
        "        for polygon in formatted_polygons:\n",
        "            cv2.polylines(img, [polygon], isClosed=True, color=(0, 0, 255), thickness=2)\n",
        "\n",
        "    # Draw area annotations (white text with black background)\n",
        "    for i, (area, center) in enumerate(zip(areas, centers)):\n",
        "        x, y = map(int, center)\n",
        "        text = f\"{area:.2f} um^2\"\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        font_scale = 0.6\n",
        "        thickness = 1\n",
        "        text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
        "        text_w, text_h = text_size\n",
        "\n",
        "        # Draw background rectangle\n",
        "        cv2.rectangle(img, (x, y - text_h), (x + text_w, y), (0, 0, 0), -1)\n",
        "        # Put text\n",
        "        cv2.putText(img, text, (x, y - 2), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Save image\n",
        "    cv2.imwrite(image_output_path, img)\n",
        "\n",
        "def output_csv(folder_name, image_name, lesion_count, conversion_ratio, areas, perimeters, csv_output_path):\n",
        "    areas_str = \"; \".join(f\"{float(a):.2f}\" for a in areas)\n",
        "    perimeters_str = \"; \".join(f\"{float(p):.2f}\" for p in perimeters)\n",
        "    conversion_ratio_str = f\"{float(conversion_ratio):.6f}\"\n",
        "\n",
        "    new_row = {\n",
        "        \"Folder\": folder_name,\n",
        "        \"Image Name\": image_name,\n",
        "        \"# Lesions\": lesion_count,\n",
        "        \"Pixels Per um\": conversion_ratio_str,\n",
        "        \"um^2\": areas_str,\n",
        "        \"Perimeters\": perimeters_str\n",
        "        }\n",
        "    new_row_df = pd.DataFrame([new_row], columns=csv_columns)\n",
        "    new_row_df.to_csv(csv_output_path, mode='a', header=not os.path.exists(csv_output_path), index=False)\n",
        "\n",
        "def output_ara(ara_location, file_directory, image_name, lesion_count, conversion_ratio, areas, perimeters, perimeters_list, height, width):\n",
        "    for i in range(0, len(areas)):\n",
        "        areas[i] = areas[i]/100000000\n",
        "        areas[i] = float(areas[i])\n",
        "        perimeters[i] = float(perimeters[i])\n",
        "\n",
        "    folder_path = file_directory + \"\\\\\" + image_name\n",
        "\n",
        "    if image_name.endswith(\".JPG\"):\n",
        "        ara_file = image_name.replace(\".JPG\", \".ara\")\n",
        "    else:\n",
        "        ara_file = image_name.replace(\".jpg\", \".ara\")\n",
        "\n",
        "    ara_file = os.path.join(ara_location, ara_file)\n",
        "\n",
        "    with open(ara_file, \"w\") as file:\n",
        "        file.write(f\"\\\"{folder_path}\\\"\\r\\n\")\n",
        "        file.write(f\"{conversion_ratio:.4f},{((height*width)/(conversion_ratio**2)):.4f},\\\"cm\\\"\\r\\n\")\n",
        "        file.write(f\"{len(areas)}\\r\\n\")\n",
        "\n",
        "        for i in range(0, len(areas)):\n",
        "            file.write(f\"{(areas[i]):.4f},{14671839},{len(perimeters_list[i])}\\r\\n\")\n",
        "            for j in perimeters_list[i]:\n",
        "                file.write(f\"{','.join(map(str, j))}\\r\\n\")\n",
        "\n",
        "        file.write(f\"5,5,\\\"Pixels/cm: {conversion_ratio:.4f}\\\"\\r\\n\")\n",
        "        file.write(f\"{len(areas)},{8}\\r\\n\")\n",
        "        file.write(f\"\\\"AREA #\\\"\\r\\n\\\"SPECIES\\\"\\r\\n\\\"SPECIES CODE\\\"\\r\\n\\\"MASTER AREA\\\"\\r\\n\\\"AREA\\\"\\r\\n\\\"INT. AREA\\\"\\r\\n\\\"EXT. AREA\\\"\\r\\n\\\"NET AREA\\\"\\r\\n\\\"COMMENTS\\\"\\r\\n\")\n",
        "\n",
        "        for a in range(0,len(areas)):\n",
        "            file.write(f\"\\\"{a+1}\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"{(areas[a]):.4f}\\\"\\r\\n\\\"{(areas[a]):.4f}\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"{(areas[a]):.4f}\\\"\\r\\n\\\"\\\"\\r\\n\")\n",
        "\n",
        "        file.write(f\"{855}\\r\\n{2040}\\r\\n{1515}\\r\\n{1500}\\r\\n{1275}\\r\\n{1275}\\r\\n{1275}\\r\\n{1275}\\r\\n{14475}\\r\\n{0}\\r\\n{0}\\r\\n\")\n",
        "\n",
        "        for a in range(0, len(areas)):\n",
        "            file.write(f\"{0}\\r\\n\")\n",
        "\n",
        "        for a in range(0, len(areas)):\n",
        "            file.write(f\"0,0,0,0,0,\\\"\\\"\\r\\n\")\n",
        "\n",
        "        file.write(f\"\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\\\"\\\"\\r\\n\")\n",
        "\n",
        "def append_row_to_excel(file_path, new_row_dict):\n",
        "    if os.path.exists(file_path):\n",
        "        df_existing = pd.read_excel(file_path)\n",
        "        # Check if date already exists\n",
        "        if new_row_dict['Date'] in df_existing['Date'].values:\n",
        "            #print(f\"Skipping duplicate date {new_row_dict['Date']} in {file_path}\")\n",
        "            return\n",
        "        df_existing = pd.concat([df_existing, pd.DataFrame([new_row_dict])], ignore_index=True)\n",
        "        df_existing = df_existing.sort_values(by='Date')\n",
        "        df_existing.to_excel(file_path, index=False)\n",
        "    else:\n",
        "        pd.DataFrame([new_row_dict]).to_excel(file_path, index=False)\n",
        "\n",
        "def output_conversion_ratios(path, conversion_ratios):\n",
        "     with open(path, 'w') as f:\n",
        "        json.dump(conversion_ratios, f, indent=4)\n",
        "\n",
        "def get_metadata(index, image_name, height, width, bboxes, segmentations):\n",
        "    image_info = {\n",
        "        \"id\": index,\n",
        "        \"license\": 1,\n",
        "        \"file_name\": image_name,\n",
        "        \"height\": height,\n",
        "        \"width\": width,\n",
        "        \"date_captured\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "    annotations = []\n",
        "    for annotation_id, (bbox, segmentation) in enumerate(zip(bboxes, segmentations)):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        width_box = x_max - x_min\n",
        "        height_box = y_max - y_min\n",
        "        area = width_box * height_box\n",
        "\n",
        "        annotation_info = {\n",
        "            \"id\": index * 1000 + annotation_id,  # ensures uniqueness\n",
        "            \"image_id\": index,\n",
        "            \"category_id\": 1,\n",
        "            \"bbox\": [x_min, y_min, width_box, height_box],\n",
        "            \"area\": area,\n",
        "            \"segmentation\": segmentation,\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "        annotations.append(annotation_info)\n",
        "    return image_info, annotations\n",
        "\n",
        "def output_coco_json(image_info_list, annotations_list, output_path):\n",
        "    coco_dict = {\n",
        "        \"info\": {\n",
        "            \"description\": \"Coral Dataset\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2025,\n",
        "            \"contributor\": \"Richard Zhao\",\n",
        "            \"date_created\": datetime.datetime.now().isoformat()\n",
        "        },\n",
        "        \"licenses\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "            }\n",
        "        ],\n",
        "        \"images\": image_info_list,\n",
        "        \"annotations\": annotations_list,\n",
        "        \"categories\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"coral_lesion\",\n",
        "                \"supercategory\": \"marine_life\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save to JSON file\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(coco_dict, f, indent=4)\n",
        "\n",
        "class ClickCollector:\n",
        "    def __init__(self, image, image_name=\"Image\", on_done=None):\n",
        "        self.image = image\n",
        "        self.image_name = image_name\n",
        "        self.on_done = on_done\n",
        "        self.coords = []\n",
        "        self.line = None\n",
        "        self.dots = []\n",
        "        self.click_mode = False\n",
        "\n",
        "        self.out = Output()\n",
        "\n",
        "        # Setup plot\n",
        "        with self.out:\n",
        "            self.fig, self.ax = plt.subplots(figsize=(8,6))\n",
        "            self.ax.imshow(self.image)\n",
        "            self.ax.set_title(f\"{self.image_name}\")\n",
        "            self.cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
        "            plt.show()\n",
        "\n",
        "        # Buttons\n",
        "        self.click_button = Button(description=\"Enable Click Mode\", button_style='primary')\n",
        "        self.click_button.on_click(self.toggle_click_mode)\n",
        "\n",
        "        self.clear_button = Button(description=\"Clear\", button_style='danger')\n",
        "        self.clear_button.on_click(self.clear)\n",
        "\n",
        "        self.finish_button = Button(description=\"Finish\", button_style='success')\n",
        "        self.finish_button.on_click(self.finish)\n",
        "\n",
        "        self.reload_button = Button(description=\"Reload Image\", button_style='info')\n",
        "        self.reload_button.on_click(self.reload_image)\n",
        "\n",
        "        # Distance input & submit button, hidden initially\n",
        "        self.dist_input = widgets.FloatText(description=\"Real distance (cm):\")\n",
        "        self.dist_submit = widgets.Button(description=\"Submit distance\")\n",
        "        self.dist_submit.on_click(self.submit_distance)\n",
        "        self.dist_input.layout.display = 'none'\n",
        "        self.dist_submit.layout.display = 'none'\n",
        "\n",
        "        # Manual ratio input & submit button\n",
        "        self.ratio_input = widgets.FloatText(description=\"Pixels/cm:\")\n",
        "        self.ratio_submit = widgets.Button(description=\"Use Ratio Directly\")\n",
        "        self.ratio_submit.on_click(self.submit_ratio_directly)\n",
        "\n",
        "        self.ui = VBox([ #Make ui more user friendly\n",
        "            self.out,\n",
        "            HBox([self.click_button, self.clear_button, self.finish_button, self.reload_button]),\n",
        "            VBox([\n",
        "                Label(\"Option 1: Calibrate by clicking two points on the image\"),\n",
        "                self.dist_input, self.dist_submit,\n",
        "                Label(\"Option 2: Or enter pixels per cm directly\"),\n",
        "                self.ratio_input, self.ratio_submit\n",
        "            ])\n",
        "        ])\n",
        "        display(self.ui)\n",
        "\n",
        "    def toggle_click_mode(self, b):\n",
        "        self.click_mode = not self.click_mode\n",
        "        if self.click_mode:\n",
        "            self.click_button.description = \"Click Mode: ON (Click Image)\"\n",
        "            self.click_button.button_style = 'warning'\n",
        "        else:\n",
        "            self.click_button.description = \"Click Mode: OFF\"\n",
        "            self.click_button.button_style = 'primary'\n",
        "\n",
        "    def onclick(self, event):\n",
        "        if not self.click_mode or event.inaxes != self.ax:\n",
        "            return\n",
        "        x, y = event.xdata, event.ydata\n",
        "        self.coords.append((x, y))\n",
        "        self.draw_dot(x, y)\n",
        "        if len(self.coords) == 2:\n",
        "            self.draw_line()\n",
        "            self.toggle_click_mode(None)\n",
        "\n",
        "    def draw_dot(self, x, y):\n",
        "        dot = self.ax.plot(x, y, 'ro', markersize=6)[0]\n",
        "        self.dots.append(dot)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def draw_line(self):\n",
        "        x_vals = [self.coords[0][0], self.coords[1][0]]\n",
        "        y_vals = [self.coords[0][1], self.coords[1][1]]\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "        self.line, = self.ax.plot(x_vals, y_vals, 'r-', linewidth=2)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def clear(self, b):\n",
        "        # Clear all dots\n",
        "        for dot in self.dots:\n",
        "            dot.remove()\n",
        "        self.dots = []\n",
        "\n",
        "        # Clear line\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "            self.line = None\n",
        "\n",
        "        self.coords = []\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def finish(self, b):\n",
        "        if len(self.coords) != 2:\n",
        "            with self.out:\n",
        "                print(\"Please click exactly 2 points before finishing.\")\n",
        "            return\n",
        "        with self.out:\n",
        "            print(f\"✅ Line set from {self.coords[0]} to {self.coords[1]}\")\n",
        "            print(\"Please enter the real-world distance (cm) below:\")\n",
        "        # Show distance input widgets\n",
        "        self.dist_input.layout.display = None\n",
        "        self.dist_submit.layout.display = None\n",
        "        self.ratio_input.layout.display = None\n",
        "        self.ratio_submit.layout.display = None\n",
        "\n",
        "    def submit_distance(self, b):\n",
        "        dist = self.dist_input.value\n",
        "        if dist <= 0:\n",
        "            with self.out:\n",
        "                print(\"Distance must be positive.\")\n",
        "            return\n",
        "        pixel_dist = np.linalg.norm(np.array(self.coords[0]) - np.array(self.coords[1]))\n",
        "        ratio = pixel_dist / dist\n",
        "        with self.out:\n",
        "            print(f\"➡️ Pixel distance: {pixel_dist:.2f}\")\n",
        "            print(f\"➡️ Real distance: {dist:.2f} cm\")\n",
        "            print(f\"➡️ Conversion ratio: {ratio:.2f} pixels/cm\")\n",
        "        if self.on_done:\n",
        "            self.on_done(ratio)\n",
        "            plt.close(self.fig) #May cause the image to be blank, need to check, maybe add a 4th button to reload the plot\n",
        "\n",
        "    def submit_ratio_directly(self, b):\n",
        "        ratio = self.ratio_input.value\n",
        "        if ratio <= 0:\n",
        "            with self.out:\n",
        "                print(\"Ratio must be positive.\")\n",
        "            return\n",
        "        with self.out:\n",
        "            print(f\"➡️ Using manually entered ratio: {ratio:.2f} pixels/cm\")\n",
        "        if self.on_done:\n",
        "            self.on_done(ratio)\n",
        "            plt.close(self.fig)\n",
        "\n",
        "    def reload_image(self, b):\n",
        "        # Clear previous plot\n",
        "        plt.close(self.fig)\n",
        "        self.coords = []\n",
        "        self.line = None\n",
        "        self.dots = []\n",
        "\n",
        "        with self.out:\n",
        "            clear_output(wait=True)  # Clear previous output safely\n",
        "            self.fig, self.ax = plt.subplots(figsize=(8,6))\n",
        "            self.ax.imshow(self.image)\n",
        "            self.ax.set_title(f\"{self.image_name}\")\n",
        "            self.cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
        "            plt.show()\n",
        "\n",
        "        # Reset button states\n",
        "        self.click_button.description = \"Enable Click Mode\"\n",
        "        self.click_button.button_style = 'primary'\n",
        "        self.click_mode = False\n",
        "\n",
        "def extract_coco_info(coco_data):\n",
        "    # Step 1: Map image_id → original filename\n",
        "    image_id_to_name = {}\n",
        "    for img in coco_data[\"images\"]:\n",
        "        original_name = img.get(\"extra\", {}).get(\"name\")\n",
        "        if original_name:\n",
        "            image_id_to_name[img[\"id\"]] = original_name\n",
        "\n",
        "    # Step 2: Build result dict: original_name → list of annotations\n",
        "    annotations_by_filename = {}\n",
        "    for ann in coco_data[\"annotations\"]:\n",
        "        image_id = ann[\"image_id\"]\n",
        "        original_name = image_id_to_name.get(image_id)\n",
        "        if original_name:\n",
        "            annotations_by_filename.setdefault(original_name, []).append(ann)\n",
        "\n",
        "    return annotations_by_filename\n",
        "\n",
        "def get_original_filename(coco_data, roboflow_filename):\n",
        "    for image in coco_data[\"images\"]:\n",
        "        if image[\"file_name\"] == roboflow_filename:\n",
        "            name = image.get(\"extra\", {}).get(\"name\")\n",
        "            return name\n",
        "    return None\n",
        "\n",
        "def format_original_filename(name):\n",
        "    new_name = re.sub(r'-(\\d+)-', r' (\\1)', name)\n",
        "    return new_name\n",
        "\n",
        "def extract_conversion_ratios_json(path):\n",
        "    with open(path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "def convert_coco_to_xyxy(bboxes):\n",
        "    converted = []\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, width, height = bbox\n",
        "        x_max = x_min + width\n",
        "        y_max = y_min + height\n",
        "        converted.append([x_min, y_min, x_max, y_max])\n",
        "    return converted"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7",
      "metadata": {
        "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7"
      },
      "source": [
        "## Run Measurer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "02b177ee7a8a4e959dc26e33d627ae10",
            "2a10be9d705b415e8ac0a13955ad988a"
          ]
        },
        "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f",
        "outputId": "71ba3844-2c0b-48d0-cf95-ffe2edd8d185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter directory where unnanotated coral lesion files are located (i.e. C:\\Users\\myself\\Downloads\\folder): C:\\Users\\myself\\Downloads\\folder\n",
            "Starting Processing...\n",
            "Processed 'LC-003_2022_03_02 (2).JPG': Conversion ratio = 67.72 pixels/cm, Lesions detected = 11, Areas calculated = 11, Perimeters calculated = 11\n",
            "Processed 'RRC_S2_ECA_LC-003_ab_2021_11_29 (2).JPG': Conversion ratio = 68.03 pixels/cm, Lesions detected = 5, Areas calculated = 5, Perimeters calculated = 5\n",
            "Processed 'LC-013 2023.05.03.JPG': Conversion ratio = 69.27 pixels/cm, Lesions detected = 2, Areas calculated = 2, Perimeters calculated = 2\n",
            "Processed 'LC-016 2023.05.03.JPG': Conversion ratio = 69.61 pixels/cm, Lesions detected = 6, Areas calculated = 5, Perimeters calculated = 5\n",
            "Successfully Finished Processing Automatic Images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02b177ee7a8a4e959dc26e33d627ae10"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "image_input_root = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/Input/\"\n",
        "\n",
        "image_input_path = [\n",
        "    os.path.join(root, d)\n",
        "    for root, dirs, _ in os.walk(image_input_root)\n",
        "    for d in dirs\n",
        "]\n",
        "image_input_path.append(image_input_root)\n",
        "\n",
        "image_output_path = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/Output/\"\n",
        "csv_output_path = image_output_path + \"/coral_lesion_data.csv\"\n",
        "csv_columns = [\"Folder\", \"Image Name\", \"# Lesions\", \"Pixels Per um\", \"um^2\", \"Perimeters\"]\n",
        "\n",
        "areas_folder = os.path.join(image_output_path, \"areas\")\n",
        "ara_folder = os.path.join(image_output_path, \"ara\")\n",
        "os.makedirs(ara_folder, exist_ok=True)\n",
        "error_folder = os.path.join(image_output_path, \"error\")\n",
        "os.makedirs(error_folder, exist_ok=True)\n",
        "file_directory = input(\"Enter directory where unnanotated coral lesion files are located (i.e. C:\\\\Users\\\\myself\\\\Downloads\\\\folder): \") #Make a big print to explain the weird aspect\n",
        "perimeters_folder = os.path.join(image_output_path, \"perimeters\")\n",
        "os.makedirs(areas_folder, exist_ok=True)\n",
        "os.makedirs(perimeters_folder, exist_ok=True)\n",
        "\n",
        "json_output_path = os.path.join(image_output_path, \"_annotations.coco.json\")\n",
        "conversion_ratios_output_path = os.path.join(image_output_path, \"conversion_ratios.json\")\n",
        "\n",
        "pending_conversion = {}\n",
        "conversion_ratios = {}\n",
        "image_metadata_list = []\n",
        "annotation_metadata_list = []\n",
        "image_index = 0\n",
        "\n",
        "print(\"Starting Processing...\")\n",
        "\n",
        "for index, folder in enumerate(image_input_path):\n",
        "    folder_name = os.path.basename(folder.rstrip('/'))\n",
        "    for file in os.listdir(folder):\n",
        "        if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "            old_image_path = os.path.join(folder, file)\n",
        "            image_name, _ = os.path.splitext(file)\n",
        "            new_image_path = os.path.join(image_output_path, file)\n",
        "            image, height, width = open_image(old_image_path)\n",
        "\n",
        "            conversion_ratio, conversion_bbox = get_pvc_ratio(image, file)\n",
        "            if conversion_ratio is None:\n",
        "                conversion_ratio, conversion_bbox = get_conversion_ratio(image, file)\n",
        "                if conversion_ratio is None:\n",
        "                    pending_conversion[file] = (image, height, width, old_image_path)\n",
        "                    continue\n",
        "            conversion_ratios[file] = conversion_ratio\n",
        "\n",
        "            bboxes_lesion = run_yolo_lesion(image)\n",
        "            if not bboxes_lesion:\n",
        "                !cp \"{old_image_path}\" \"{error_folder}\"\n",
        "                print(\"No BBoxes in \" + file + \"\\n\")\n",
        "                continue\n",
        "            masks_lesion = run_sam(image, bboxes_lesion)\n",
        "            filtered = overlap_filtering(bboxes_lesion, masks_lesion, iou_thresh=0.85)\n",
        "            filtered_bboxes, filtered_masks = zip(*filtered) if filtered else ([], [])\n",
        "            segmentations = masks_to_polygons(filtered_masks)\n",
        "            perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "            perimeter_points = get_perimeter_list(segmentations)\n",
        "            areas, centers = get_areas_and_centers_from_polygons(segmentations, filtered_bboxes, conversion_ratio)\n",
        "            id, date, repetition = image_info(image_name)\n",
        "\n",
        "            area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "            perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "            output_ara(ara_folder, file_directory, file, len(masks_lesion), conversion_ratio, areas, perimeters, perimeter_points, height, width)\n",
        "\n",
        "            area_row = {'Date': date}\n",
        "            for i, a in enumerate(areas):\n",
        "                area_row[f'Area {i+1}'] = float(f\"{a:.2f}\")\n",
        "\n",
        "            perim_row = {'Date': date}\n",
        "            for i, p in enumerate(perimeters):\n",
        "                perim_row[f'Perimeter {i+1}'] = float(f\"{p:.2f}\")\n",
        "\n",
        "            append_row_to_excel(area_file, area_row)\n",
        "            append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "            output_image_cv(image, conversion_ratio, conversion_bbox, filtered_bboxes, filtered_masks, segmentations, areas, centers, new_image_path)\n",
        "            output_csv(folder_name, file, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "            image_metadata, annotation_metadata = get_metadata(image_index, file, height, width, bboxes_lesion, segmentations)\n",
        "            image_metadata_list.append(image_metadata)\n",
        "            annotation_metadata_list.extend(annotation_metadata)\n",
        "\n",
        "            print(f\"Processed '{file}': Conversion ratio = {conversion_ratio:.2f} pixels/cm, \"\n",
        "                f\"Lesions detected = {len(bboxes_lesion)}, \"\n",
        "                f\"Areas calculated = {len(areas)}, Perimeters calculated = {len(perimeters)}\")\n",
        "\n",
        "            image_index += 1\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "if image_metadata_list and annotation_metadata_list and conversion_ratio and not pending_conversion:\n",
        "    output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "    output_conversion_ratios(conversion_ratios_output_path, conversion_ratios)\n",
        "\n",
        "print(\"Successfully Finished Processing Automatic Images\")\n",
        "\n",
        "resolved_ratios = {}\n",
        "pending_items = list(pending_conversion.items())\n",
        "current_idx = 0\n",
        "main_output = widgets.Output()\n",
        "display(main_output)\n",
        "\n",
        "def process_next():\n",
        "    global current_idx\n",
        "    if current_idx >= len(pending_items):\n",
        "        with main_output:\n",
        "            clear_output()\n",
        "            print(\"All manual ratios collected. Restarting Processing...\")\n",
        "        run_analysis()\n",
        "        return\n",
        "\n",
        "    image_name, (image, height, width, old_image_path) = pending_items[current_idx]\n",
        "    current_idx += 1\n",
        "\n",
        "    def handle_ratio(ratio):\n",
        "        resolved_ratios[image_name] = ratio\n",
        "        process_next()\n",
        "\n",
        "    with main_output:\n",
        "        clear_output(wait=True)\n",
        "        ClickCollector(image, image_name, on_done=handle_ratio)\n",
        "\n",
        "def run_analysis():\n",
        "    global image_index\n",
        "    for image_name, conversion_ratio in resolved_ratios.items():\n",
        "        if conversion_ratio is None:\n",
        "            continue\n",
        "        conversion_ratios[image_name] = conversion_ratio\n",
        "\n",
        "        image, height, width, old_image_path = pending_conversion[image_name]\n",
        "        new_image_path = os.path.join(image_output_path, image_name)\n",
        "\n",
        "        bboxes_lesion = run_yolo_lesion(image)\n",
        "        if not bboxes_lesion:\n",
        "              !cp \"{old_image_path}\" \"{error_folder}\"\n",
        "              print(\"No BBoxes in \" + file + \"\\n\")\n",
        "              continue\n",
        "        masks_lesion = run_sam(image, bboxes_lesion)\n",
        "        filtered = overlap_filtering(bboxes_lesion, masks_lesion, iou_thresh=0.85)\n",
        "        filtered_bboxes, filtered_masks = zip(*filtered) if filtered else ([], [])\n",
        "        segmentations = masks_to_polygons(filtered_masks)\n",
        "        perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "        areas, centers = get_areas_and_centers(filtered_masks, filtered_bboxes, conversion_ratio)\n",
        "        id, date, repetition = image_info(image_name)\n",
        "\n",
        "        # Excel\n",
        "        area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "        perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "\n",
        "        area_row = {'Date': date}\n",
        "        for i, a in enumerate(areas):\n",
        "            area_row[f'Area {i+1}'] = float(f\"{a:.2f}\")\n",
        "\n",
        "        perim_row = {'Date': date}\n",
        "        for i, p in enumerate(perimeters):\n",
        "            perim_row[f'Perimeter {i+1}'] = float(f\"{p:.2f}\")\n",
        "\n",
        "        append_row_to_excel(area_file, area_row)\n",
        "        append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "        output_image_cv(image, conversion_ratio, None, filtered_bboxes, filtered_masks, segmentations, areas, centers, new_image_path)\n",
        "        output_csv(\"manual_conversion\", image_name, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "        image_metadata, annotation_metadata = get_metadata(image_index, image_name, height, width, bboxes_lesion, segmentations)\n",
        "        image_metadata_list.append(image_metadata)\n",
        "        annotation_metadata_list.extend(annotation_metadata)\n",
        "\n",
        "        with main_output:\n",
        "            print(f\"Processed '{image_name}': Conversion ratio = {conversion_ratio:.2f} pixels/cm, \"\n",
        "                f\"Lesions detected = {len(bboxes_lesion)}, \"\n",
        "                f\"Areas calculated = {len(areas)}, Perimeters calculated = {len(perimeters)}\")\n",
        "\n",
        "        image_index += 1\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if image_metadata_list and annotation_metadata_list and conversion_ratios:\n",
        "        output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "        output_conversion_ratios(conversion_ratios_output_path, conversion_ratios)\n",
        "\n",
        "    with main_output:\n",
        "        print(\"Successfully Finished Processing Manual Images\")\n",
        "\n",
        "if pending_conversion:\n",
        "    process_next()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ssrrpvTz4MPf",
      "metadata": {
        "id": "ssrrpvTz4MPf"
      },
      "source": [
        "## Run Reprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rJ5XAaB_4KCr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ5XAaB_4KCr",
        "outputId": "43cf5ccd-4c29-46f4-aa14-102c90c2e68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Reprocessing...\n",
            "Processed 'LC-077_2022_04_08 (1).JPG': Conversion ratio = 65.72 pixels/cm, Lesions detected = 10, Areas calculated = 10, Perimeters calculated = 10\n",
            "Processed 'MC-011_2022_04_08 (1).JPG': Conversion ratio = 65.96 pixels/cm, Lesions detected = 11, Areas calculated = 11, Perimeters calculated = 11\n",
            "Processed 'LC-003_2025_01_07 (3).JPG': Conversion ratio = 132.44 pixels/cm, Lesions detected = 1, Areas calculated = 1, Perimeters calculated = 1\n",
            "Processed 'RRC_S2_ECA_LC-003_ab_2021_10_06 (2).JPG': Conversion ratio = 77.62 pixels/cm, Lesions detected = 6, Areas calculated = 6, Perimeters calculated = 6\n",
            "Successfully Finished Reprocessing Images\n"
          ]
        }
      ],
      "source": [
        "adjusted_input_root = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/Reprocessing/\"\n",
        "\n",
        "adjusted_input_path = [\n",
        "    os.path.join(root, d)\n",
        "    for root, dirs, _ in os.walk(adjusted_input_root)\n",
        "    for d in dirs\n",
        "]\n",
        "adjusted_input_path.append(adjusted_input_root)\n",
        "\n",
        "conversion_ratios_input_path = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/Reprocessing/conversion_ratios.json\"\n",
        "\n",
        "image_output_path = \"/content/gdrive/MyDrive/Coral Lesion Measurer Folder/Output/\"\n",
        "csv_output_path = image_output_path + \"/coral_lesion_data.csv\"\n",
        "csv_columns = [\"Folder\", \"Image Name\", \"# Lesions\", \"Pixels Per um\", \"um^2\", \"Perimeters\"]\n",
        "\n",
        "areas_folder = os.path.join(image_output_path, \"areas\")\n",
        "perimeters_folder = os.path.join(image_output_path, \"perimeters\")\n",
        "os.makedirs(areas_folder, exist_ok=True)\n",
        "os.makedirs(perimeters_folder, exist_ok=True)\n",
        "\n",
        "json_output_path = os.path.join(image_output_path, \"_annotations.coco.json\")\n",
        "conversion_ratios_output_path = os.path.join(image_output_path, \"conversion_ratios.json\")\n",
        "\n",
        "image_metadata_list = []\n",
        "annotation_metadata_list = []\n",
        "image_index = 0\n",
        "\n",
        "print(\"Starting Reprocessing...\")\n",
        "\n",
        "for index, folder in enumerate(adjusted_input_path):\n",
        "    folder_name = os.path.basename(folder.rstrip('/'))\n",
        "    coco_path = os.path.join(folder, \"_annotations.coco.json\")\n",
        "    if not os.path.isfile(coco_path):\n",
        "        continue\n",
        "    with open(coco_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    annotations_by_filename = extract_coco_info(coco_data)\n",
        "    conversion_ratios = extract_conversion_ratios_json(conversion_ratios_input_path)\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "            old_image_path = os.path.join(folder, file)\n",
        "            image_name = get_original_filename(coco_data, file)\n",
        "            formatted_image_name = format_original_filename(image_name)\n",
        "            new_image_path = os.path.join(image_output_path, formatted_image_name)\n",
        "            image, height, width = open_image(old_image_path)\n",
        "\n",
        "            conversion_ratio = conversion_ratios[formatted_image_name]\n",
        "\n",
        "            annotations = annotations_by_filename.get(image_name)\n",
        "            annotations = [a for a in annotations if a.get(\"segmentation\")]\n",
        "            bboxes_lesion = [a[\"bbox\"] for a in annotations]\n",
        "            bboxes_lesion = convert_coco_to_xyxy(bboxes_lesion)\n",
        "            segmentations = [a[\"segmentation\"] for a in annotations]\n",
        "            areas = [a[\"area\"] for a in annotations]\n",
        "            perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "            areas, centers = get_areas_and_centers_from_polygons(segmentations, bboxes_lesion, conversion_ratio)\n",
        "            id, date, repetition = image_info(image_name)\n",
        "\n",
        "            area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "            perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "\n",
        "            area_row = {'Date': date}\n",
        "            for i, a in enumerate(areas):\n",
        "                area_row[f'Area {i+1}'] = float(f\"{a:.2f}\")\n",
        "\n",
        "            perim_row = {'Date': date}\n",
        "            for i, p in enumerate(perimeters):\n",
        "                perim_row[f'Perimeter {i+1}'] = float(f\"{p:.2f}\")\n",
        "\n",
        "            append_row_to_excel(area_file, area_row)\n",
        "            append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "            output_image_cv(image, conversion_ratio, None, bboxes_lesion, None, segmentations, areas, centers, new_image_path)\n",
        "            output_csv(folder_name, formatted_image_name, len(areas), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "            image_metadata, annotation_metadata = get_metadata(image_index, formatted_image_name, height, width, bboxes_lesion, segmentations)\n",
        "            image_metadata_list.append(image_metadata)\n",
        "            annotation_metadata_list.extend(annotation_metadata)\n",
        "\n",
        "            print(f\"Processed '{formatted_image_name}': Conversion ratio = {conversion_ratio:.2f} pixels/cm, \"\n",
        "                f\"Lesions detected = {len(bboxes_lesion)}, \"\n",
        "                f\"Areas calculated = {len(areas)}, Perimeters calculated = {len(perimeters)}\")\n",
        "\n",
        "            image_index += 1\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "if image_metadata_list and annotation_metadata_list and conversion_ratios:\n",
        "    output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "    output_conversion_ratios(conversion_ratios_output_path, conversion_ratios)\n",
        "\n",
        "print(\"Successfully Finished Reprocessing Images\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3Y68KXcf6KIc",
        "1ea15c2e-9fac-428a-bc90-cd4f717efca7",
        "ssrrpvTz4MPf"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b177ee7a8a4e959dc26e33d627ae10": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_2a10be9d705b415e8ac0a13955ad988a",
            "msg_id": "",
            "outputs": []
          }
        },
        "2a10be9d705b415e8ac0a13955ad988a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}