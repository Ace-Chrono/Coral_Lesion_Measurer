{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ace-Chrono/Coral_Lesion_Measurer/blob/main/Lesion_Measurer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Google Drive Linking"
      ],
      "metadata": {
        "id": "NF0CUrxvI72N"
      },
      "id": "NF0CUrxvI72N"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files"
      ],
      "metadata": {
        "id": "2x7yeyCpJBZ3"
      },
      "id": "2x7yeyCpJBZ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "IvRz2D2eJCGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2984b961-5766-4c64-bffc-217b42df99d1"
      },
      "id": "IvRz2D2eJCGb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3a1403c-d706-479d-b5bf-fb173e48cdd1",
      "metadata": {
        "id": "d3a1403c-d706-479d-b5bf-fb173e48cdd1"
      },
      "source": [
        "## PyTorch Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0c79fc-88f6-4418-bc2e-b6695efd59e0",
      "metadata": {
        "id": "6f0c79fc-88f6-4418-bc2e-b6695efd59e0"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad98d3a-5fc4-4f04-b9ac-0131cc4ab833",
      "metadata": {
        "id": "8ad98d3a-5fc4-4f04-b9ac-0131cc4ab833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771bf527-af79-4d23-fe0f-c5e59594c67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(torch.__version__)\n",
        "print(DEVICE) #Make sure to reload Anaconda if it prints out CPU even though it is the right PyTorch version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48d4d53d-84ad-477b-be3b-3b150b555b42",
      "metadata": {
        "id": "48d4d53d-84ad-477b-be3b-3b150b555b42"
      },
      "source": [
        "## YOLO Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573beb73-c95e-4c47-9d71-202619b25e13",
      "metadata": {
        "id": "573beb73-c95e-4c47-9d71-202619b25e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31953822-aa11-47bc-dd97-590819cdb528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.158)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics #This is where we get the YOLO packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f887af9-9d91-4512-8629-1098c6753012",
      "metadata": {
        "id": "4f887af9-9d91-4512-8629-1098c6753012"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c08e293-27d4-4772-a029-195a5304fe8e",
      "metadata": {
        "id": "8c08e293-27d4-4772-a029-195a5304fe8e"
      },
      "outputs": [],
      "source": [
        "lesion_bbox_model = YOLO(\"/content/gdrive/MyDrive/Colab Notebooks/Prototype Code/ML Models/YOLOV11_Lesion.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee442dc-3cc5-42e2-a3aa-236b5abfab1b",
      "metadata": {
        "id": "bee442dc-3cc5-42e2-a3aa-236b5abfab1b"
      },
      "outputs": [],
      "source": [
        "ruler_bbox_model = YOLO(\"/content/gdrive/MyDrive/Colab Notebooks/Prototype Code/ML Models/YOLOV11_Ruler.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00cb2e62-cb62-4492-9319-feef3d6d2637",
      "metadata": {
        "id": "00cb2e62-cb62-4492-9319-feef3d6d2637"
      },
      "source": [
        "## SAM Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9789755c-6733-4125-b936-b162b6ab5621",
      "metadata": {
        "scrolled": true,
        "id": "9789755c-6733-4125-b936-b162b6ab5621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccff03d8-6df5-442d-9974-478ebe9eb94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sam2_repo' already exists and is not an empty directory.\n",
            "/content/sam2_repo\n",
            "Obtaining file:///content/sam2_repo\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.3.2)\n",
            "Requirement already satisfied: iopath>=0.1.10 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.1.10)\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.2.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.14.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Building wheels for collected packages: SAM-2\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=SAM_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13744 sha256=e0bcaeba26e3db35a8e85e4f2b2c0e9b8f45c82f02419525ea802d4e4f31944d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-98y8xp85/wheels/a3/2c/d5/dfadcadd6d3d572079cd6218a4b7ec6885fa349c5ba7335b4b\n",
            "Successfully built SAM-2\n",
            "Installing collected packages: SAM-2\n",
            "  Attempting uninstall: SAM-2\n",
            "    Found existing installation: SAM-2 1.0\n",
            "    Uninstalling SAM-2-1.0:\n",
            "      Successfully uninstalled SAM-2-1.0\n",
            "Successfully installed SAM-2-1.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/sam2.git sam2_repo\n",
        "%cd sam2_repo\n",
        "!pip install -e . --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b184bbda-ae7f-4607-905f-5e73e722fb7e",
      "metadata": {
        "id": "b184bbda-ae7f-4607-905f-5e73e722fb7e"
      },
      "outputs": [],
      "source": [
        "#If doesn't work after cloning sam2, restart anaconda and should fix any shadowing or other glitches\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b38629-bb75-428a-b932-8d0a819e9256",
      "metadata": {
        "id": "66b38629-bb75-428a-b932-8d0a819e9256"
      },
      "outputs": [],
      "source": [
        "sam_location = \"/content/gdrive/MyDrive/Colab Notebooks/Prototype Code/ML Models/sam2.1_hiera_large.pt\"\n",
        "sam_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "lesion_sam_model = SAM2ImagePredictor(build_sam2(sam_cfg, sam_location))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GUI Setup"
      ],
      "metadata": {
        "id": "4Zm05L2bzuR8"
      },
      "id": "4Zm05L2bzuR8"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade ipympl"
      ],
      "metadata": {
        "id": "gTAgPny7zwtD"
      },
      "id": "gTAgPny7zwtD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Libraries"
      ],
      "metadata": {
        "id": "gWIWE-_oz1EP"
      },
      "id": "gWIWE-_oz1EP"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import json\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Button, Output, VBox, HBox\n",
        "from IPython.display import display, clear_output\n",
        "import os\n",
        "import gc\n",
        "import re"
      ],
      "metadata": {
        "id": "itOjos5Yz3ss"
      },
      "id": "itOjos5Yz3ss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "236f979c-0c30-4d49-84cf-e7d9885731e7",
      "metadata": {
        "id": "236f979c-0c30-4d49-84cf-e7d9885731e7"
      },
      "source": [
        "## YOLO and SAM Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c607b5a5-13a7-4921-b467-564d6869a42f",
      "metadata": {
        "id": "c607b5a5-13a7-4921-b467-564d6869a42f"
      },
      "outputs": [],
      "source": [
        "def open_image(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    height, width, channels = image_np.shape\n",
        "    return image, height, width\n",
        "\n",
        "def image_info(image_name):\n",
        "    date = None\n",
        "    repetition = None\n",
        "    id = None\n",
        "\n",
        "    parentheses_match = re.search(r'\\s*\\((\\d+)\\)$', image_name)\n",
        "    if parentheses_match:\n",
        "       repetition = int(parentheses_match.group(1))\n",
        "       image_name_clean = re.sub(r'\\s*\\(\\d+\\)$', '', image_name)\n",
        "    else:\n",
        "        image_name_clean = image_name\n",
        "\n",
        "    date_match = re.search(r'(\\d{4}_\\d{2}_\\d{2})', image_name_clean)\n",
        "    if date_match:\n",
        "        date_str = date_match.group(1)\n",
        "        date = date_str.replace('_', '-')\n",
        "\n",
        "    id_match = re.search(r'(LC[^_\\s]*)', image_name_clean)\n",
        "    if id_match:\n",
        "        id = id_match.group(1)\n",
        "\n",
        "    return id, date, repetition\n",
        "\n",
        "def get_conversion_ratio(image, image_name):\n",
        "    try:\n",
        "        results = ruler_bbox_model.predict(image, verbose=False)\n",
        "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
        "            bboxes = results[0].boxes\n",
        "            if len(bboxes.xyxy) > 0:\n",
        "                x_min, y_min, x_max, y_max = bboxes.xyxy[0].tolist()\n",
        "                width = x_max - x_min\n",
        "                height = y_max - y_min\n",
        "                conversion_ratio = max(width, height) / 32\n",
        "                print(f\"Ruler detected in {image_name}: {conversion_ratio:.2f} pixels/mm\")\n",
        "                return conversion_ratio\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ruler detection for {image_name}: {str(e)}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def run_yolo_lesion(image):\n",
        "    results = lesion_bbox_model.predict(image, verbose=False)\n",
        "    for result in results:\n",
        "        bboxes = result.boxes\n",
        "        bboxes = bboxes.xyxy.tolist()\n",
        "    return bboxes\n",
        "\n",
        "def run_sam(image, bboxes):\n",
        "    bboxes_np = []\n",
        "    for bbox in bboxes:\n",
        "        bbox_np = np.array(bbox)\n",
        "        bboxes_np.append(bbox_np)\n",
        "    input_boxes = np.array(bboxes_np).astype(np.float32)\n",
        "    with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "        lesion_sam_model.set_image(np.array(image))\n",
        "        masks, _, _ = lesion_sam_model.predict(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=input_boxes,               # shape: (N, 4)\n",
        "            multimask_output=False,\n",
        "        )\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa07d231-3497-4ab7-a437-685f983ee468",
      "metadata": {
        "id": "aa07d231-3497-4ab7-a437-685f983ee468"
      },
      "source": [
        "## Mask Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def masks_to_polygons(masks):  # Creates polygons from a list of SAM masks\n",
        "    all_polygons = []\n",
        "\n",
        "    for mask in masks:\n",
        "        mask = np.squeeze(mask)  # Ensures (H, W)\n",
        "\n",
        "        if mask is None:\n",
        "            raise ValueError(f\"Mask {i} is None.\")\n",
        "        if mask.ndim != 2:\n",
        "            raise ValueError(f\"Mask {i} must be 2D after squeeze, got shape {mask.shape}\")\n",
        "        if mask.shape[0] == 0 or mask.shape[1] == 0:\n",
        "            raise ValueError(f\"Mask {i} has invalid shape {mask.shape}\")\n",
        "        if not np.any(mask):\n",
        "            continue  # Skip empty masks\n",
        "\n",
        "        # Convert mask to binary if it's not already\n",
        "        if mask.max() > 1:\n",
        "            _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "        else:\n",
        "            binary_mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        polygons = []\n",
        "        for contour in contours:\n",
        "            # Simplify the contour to reduce the number of points\n",
        "            epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Extract points and flatten the list\n",
        "            polygon = approx.reshape(-1, 2).tolist()\n",
        "            flat_polygon = [point for sublist in polygon for point in sublist]\n",
        "            polygons.append(flat_polygon)\n",
        "\n",
        "        all_polygons.append(polygons)\n",
        "\n",
        "    return all_polygons\n",
        "\n",
        "def get_perimeter(all_polygons, conversion_ratio):\n",
        "  perimeters = []\n",
        "  for polygon in all_polygons:\n",
        "    for points in polygon:\n",
        "      contour = np.array(points).reshape(-1, 1, 2)\n",
        "      perimeter = cv2.arcLength(contour, True)\n",
        "      perimeter_cm = perimeter / conversion_ratio\n",
        "      perimeter_um = perimeter_cm * 10_000\n",
        "      perimeters.append(perimeter_um)\n",
        "\n",
        "  return perimeters\n",
        "\n",
        "def get_areas_and_centers(masks, bboxes, conversion_ratio):\n",
        "    areas = []\n",
        "    centers = []\n",
        "    for mask in masks:\n",
        "        area = np.count_nonzero(mask)\n",
        "        area_um2 = area * ((1 / conversion_ratio)*10000)** 2\n",
        "        areas.append(area_um2)\n",
        "    for bbox in bboxes:\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        center_x = (x_min + x_max) / 2\n",
        "        center_y = (y_min + y_max) / 2\n",
        "        centers.append((center_x, center_y))  # (x, y) format\n",
        "    return areas, centers"
      ],
      "metadata": {
        "id": "fAixuw23qgDS"
      },
      "id": "fAixuw23qgDS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f62fbed3-5264-4c61-83f6-790374ecc937",
      "metadata": {
        "id": "f62fbed3-5264-4c61-83f6-790374ecc937"
      },
      "source": [
        "## Annotation Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e41aa5-4c53-4f8b-9319-21f3dd97a81f",
      "metadata": {
        "id": "a9e41aa5-4c53-4f8b-9319-21f3dd97a81f"
      },
      "outputs": [],
      "source": [
        "def show_points(coords, labels, ax, marker_size=375): #Adds point prompts into the axes\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_bboxes(bboxes, ax): #Adds bounding boxes into the axes\n",
        "    for bbox in bboxes:\n",
        "        x0, y0 = bbox[0], bbox[1]\n",
        "        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "        rect = plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "def show_masks(masks, ax, random_color=False): #Adds SAM masks into the axes\n",
        "    for mask in masks:\n",
        "        if random_color:\n",
        "            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "        else:\n",
        "            color = np.array([30/255, 144/255, 255/255, 0.2])  # semi-transparent blue\n",
        "\n",
        "        h, w = mask.shape[-2:]\n",
        "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "        ax.imshow(mask_image)\n",
        "\n",
        "def show_polygons(polygons_list, ax): #Adds a polygon made from the SAM mask into the axes\n",
        "    for polygons in polygons_list:\n",
        "        formatted_polygons = [np.array(polygon).reshape(-1, 2) for polygon in polygons]\n",
        "        for polygon in formatted_polygons:\n",
        "            polygon_patch = patches.Polygon(polygon, closed=True, edgecolor='red', facecolor=(0, 0, 0, 0), lw=2)\n",
        "            ax.add_patch(polygon_patch)\n",
        "\n",
        "def show_areas(areas, centers, ax): #Adds the ground truth areas to the axes\n",
        "    for i, (area, center) in enumerate(zip(areas, centers)):\n",
        "        x, y = center\n",
        "        ax.text(x, y, str(area) + \" um^2\", color='white', fontsize=16, backgroundcolor='black')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3846155b-7747-41b6-a8db-b2bffc849dab",
      "metadata": {
        "id": "3846155b-7747-41b6-a8db-b2bffc849dab"
      },
      "source": [
        "## Outputting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7909165-7a6d-4054-903e-ef5ad7417a5d",
      "metadata": {
        "id": "b7909165-7a6d-4054-903e-ef5ad7417a5d"
      },
      "outputs": [],
      "source": [
        "def output_image(image, height, width, image_output_path, bboxes, masks, segmentations, areas, centers):\n",
        "    scale_factor = 100\n",
        "    fig, ax = plt.subplots(figsize=(width / scale_factor, height / scale_factor))\n",
        "    ax.set_position([0, 0, 1, 1])\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, aspect='auto')\n",
        "    show_bboxes(bboxes, ax)\n",
        "    show_masks(masks, ax)\n",
        "    show_polygons(segmentations, ax)\n",
        "    show_areas(areas, centers, ax)\n",
        "    fig.savefig(os.path.join(image_output_path), dpi=100)\n",
        "    plt.close(fig)\n",
        "\n",
        "def output_csv(folder_name, image_name, lesion_count, conversion_ratio, areas, perimeters, csv_output_path):\n",
        "    new_row = {\n",
        "        \"Folder\": folder_name,\n",
        "        \"Image Name\": image_name,\n",
        "        \"# Lesions\": lesion_count,\n",
        "        \"Pixels Per um\": conversion_ratio,\n",
        "        \"um^2\": areas,\n",
        "        \"Perimeters\": perimeters\n",
        "        }\n",
        "    new_row_df = pd.DataFrame([new_row], columns=csv_columns)\n",
        "    new_row_df.to_csv(csv_output_path, mode='a', header=not os.path.exists(csv_output_path), index=False)\n",
        "\n",
        "def get_metadata(index, image_name, height, width, bboxes, segmentations):\n",
        "    image_info = {\n",
        "        \"id\": index,\n",
        "        \"license\": 1,\n",
        "        \"file_name\": image_name,\n",
        "        \"height\": height,\n",
        "        \"width\": width,\n",
        "        \"date_captured\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "    annotations = []\n",
        "    for annotation_id, (bbox, segmentation) in enumerate(zip(bboxes, segmentations)):\n",
        "        x_min, y_min, x_max, y_max = bbox\n",
        "        width_box = x_max - x_min\n",
        "        height_box = y_max - y_min\n",
        "        area = width_box * height_box\n",
        "\n",
        "        annotation_info = {\n",
        "            \"id\": index * 1000 + annotation_id,  # ensures uniqueness\n",
        "            \"image_id\": index,\n",
        "            \"category_id\": 1,\n",
        "            \"bbox\": [x_min, y_min, width_box, height_box],\n",
        "            \"area\": area,\n",
        "            \"segmentation\": segmentation,\n",
        "            \"iscrowd\": 0\n",
        "        }\n",
        "        annotations.append(annotation_info)\n",
        "    return image_info, annotations\n",
        "\n",
        "def output_coco_json(image_info_list, annotations_list, output_path):\n",
        "    coco_dict = {\n",
        "        \"info\": {\n",
        "            \"description\": \"Coral Dataset\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2025,\n",
        "            \"contributor\": \"Richard Zhao\",\n",
        "            \"date_created\": datetime.datetime.now().isoformat()\n",
        "        },\n",
        "        \"licenses\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "            }\n",
        "        ],\n",
        "        \"images\": image_info_list,\n",
        "        \"annotations\": annotations_list,\n",
        "        \"categories\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"coral lesion\",\n",
        "                \"supercategory\": \"marine_life\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Save to JSON file\n",
        "    with open(output_path, \"w\") as f:\n",
        "        json.dump(coco_dict, f, indent=4)\n",
        "\n",
        "\n",
        "def append_row_to_excel(file_path, new_row_dict):\n",
        "    if os.path.exists(file_path):\n",
        "        df_existing = pd.read_excel(file_path)\n",
        "        # Check if date already exists\n",
        "        if new_row_dict['Date'] in df_existing['Date'].values:\n",
        "            print(f\"Skipping duplicate date {new_row_dict['Date']} in {file_path}\")\n",
        "            return\n",
        "        df_existing = pd.concat([df_existing, pd.DataFrame([new_row_dict])], ignore_index=True)\n",
        "        df_existing = df_existing.sort_values(by='Date')\n",
        "        df_existing.to_excel(file_path, index=False)\n",
        "    else:\n",
        "        pd.DataFrame([new_row_dict]).to_excel(file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Manual Conversion Ratio GUI"
      ],
      "metadata": {
        "id": "IZ31PF-I0eeH"
      },
      "id": "IZ31PF-I0eeH"
    },
    {
      "cell_type": "code",
      "source": [
        "class ClickCollector:\n",
        "    def __init__(self, image, image_name=\"Image\", on_done=None):\n",
        "        self.image = image\n",
        "        self.image_name = image_name\n",
        "        self.on_done = on_done\n",
        "        self.coords = []\n",
        "        self.line = None\n",
        "        self.dots = []\n",
        "        self.click_mode = False\n",
        "\n",
        "        self.out = Output()\n",
        "\n",
        "        # Setup plot\n",
        "        with self.out:\n",
        "            self.fig, self.ax = plt.subplots(figsize=(8,6))\n",
        "            self.ax.imshow(self.image)\n",
        "            self.ax.set_title(f\"{self.image_name}\")\n",
        "            self.cid = self.fig.canvas.mpl_connect('button_press_event', self.onclick)\n",
        "            plt.show()\n",
        "\n",
        "        # Buttons\n",
        "        self.click_button = Button(description=\"Enable Click Mode\", button_style='primary')\n",
        "        self.click_button.on_click(self.toggle_click_mode)\n",
        "\n",
        "        self.clear_button = Button(description=\"Clear\", button_style='danger')\n",
        "        self.clear_button.on_click(self.clear)\n",
        "\n",
        "        self.finish_button = Button(description=\"Finish\", button_style='success')\n",
        "        self.finish_button.on_click(self.finish)\n",
        "\n",
        "        # Distance input & submit button, hidden initially\n",
        "        self.dist_input = widgets.FloatText(description=\"Real distance (cm):\")\n",
        "        self.dist_submit = widgets.Button(description=\"Submit distance\")\n",
        "        self.dist_submit.on_click(self.submit_distance)\n",
        "        self.dist_input.layout.display = 'none'\n",
        "        self.dist_submit.layout.display = 'none'\n",
        "\n",
        "        display(VBox([\n",
        "            self.out,\n",
        "            HBox([self.click_button, self.clear_button, self.finish_button]),\n",
        "            VBox([self.dist_input, self.dist_submit])\n",
        "        ]))\n",
        "\n",
        "    def toggle_click_mode(self, b):\n",
        "        self.click_mode = not self.click_mode\n",
        "        if self.click_mode:\n",
        "            self.click_button.description = \"Click Mode: ON (Click Image)\"\n",
        "            self.click_button.button_style = 'warning'\n",
        "            print(\"🖱️ Click mode enabled: Click two points.\")\n",
        "        else:\n",
        "            self.click_button.description = \"Click Mode: OFF\"\n",
        "            self.click_button.button_style = 'primary'\n",
        "            print(\"✋ Click mode disabled: Use zoom/pan tools.\")\n",
        "\n",
        "    def onclick(self, event):\n",
        "        if not self.click_mode or event.inaxes != self.ax:\n",
        "            return\n",
        "        x, y = event.xdata, event.ydata\n",
        "        print(f\"📍 Clicked at ({x:.1f}, {y:.1f})\")\n",
        "        self.coords.append((x, y))\n",
        "        self.draw_dot(x, y)\n",
        "        if len(self.coords) == 2:\n",
        "            self.draw_line()\n",
        "            self.toggle_click_mode(None)\n",
        "\n",
        "    def draw_dot(self, x, y):\n",
        "        dot = self.ax.plot(x, y, 'ro', markersize=6)[0]\n",
        "        self.dots.append(dot)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def draw_line(self):\n",
        "        x_vals = [self.coords[0][0], self.coords[1][0]]\n",
        "        y_vals = [self.coords[0][1], self.coords[1][1]]\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "        self.line, = self.ax.plot(x_vals, y_vals, 'r-', linewidth=2)\n",
        "        self.fig.canvas.draw()\n",
        "\n",
        "    def clear(self, b):\n",
        "        # Clear all dots\n",
        "        for dot in self.dots:\n",
        "            dot.remove()\n",
        "        self.dots = []\n",
        "\n",
        "        # Clear line\n",
        "        if self.line:\n",
        "            self.line.remove()\n",
        "            self.line = None\n",
        "\n",
        "        self.coords = []\n",
        "        self.fig.canvas.draw()\n",
        "        print(\"🧹 Cleared all points and lines.\")\n",
        "\n",
        "    def finish(self, b):\n",
        "        if len(self.coords) != 2:\n",
        "            with self.out:\n",
        "                print(\"Please click exactly 2 points before finishing.\")\n",
        "            return\n",
        "        with self.out:\n",
        "            print(f\"✅ Line set from {self.coords[0]} to {self.coords[1]}\")\n",
        "            print(\"Please enter the real-world distance (cm) below:\")\n",
        "        # Show distance input widgets\n",
        "        self.dist_input.layout.display = None\n",
        "        self.dist_submit.layout.display = None\n",
        "\n",
        "    def submit_distance(self, b):\n",
        "        dist = self.dist_input.value\n",
        "        if dist <= 0:\n",
        "            with self.out:\n",
        "                print(\"Distance must be positive.\")\n",
        "            return\n",
        "        pixel_dist = np.linalg.norm(np.array(self.coords[0]) - np.array(self.coords[1]))\n",
        "        ratio = pixel_dist / dist\n",
        "        with self.out:\n",
        "            print(f\"➡️ Pixel distance: {pixel_dist:.2f}\")\n",
        "            print(f\"➡️ Real distance: {dist:.2f} cm\")\n",
        "            print(f\"➡️ Conversion ratio: {ratio:.2f} pixels/cm\")\n",
        "        if self.on_done:\n",
        "            self.on_done(ratio)"
      ],
      "metadata": {
        "id": "9cjBzzBh0g9g"
      },
      "id": "9cjBzzBh0g9g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cfb0e46b-8952-483a-95a2-f4ac63032220",
      "metadata": {
        "id": "cfb0e46b-8952-483a-95a2-f4ac63032220"
      },
      "source": [
        "## Define Path Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11fab7a8-9a13-4f73-8a76-79f38ebb9402",
      "metadata": {
        "id": "11fab7a8-9a13-4f73-8a76-79f38ebb9402"
      },
      "outputs": [],
      "source": [
        "image_input_root = \"/content/gdrive/MyDrive/Colab Notebooks/Prototype Code/Input/\"\n",
        "\n",
        "image_input_path = [\n",
        "    os.path.join(root, d)\n",
        "    for root, dirs, _ in os.walk(image_input_root)\n",
        "    for d in dirs\n",
        "]\n",
        "image_input_path.append(image_input_root)\n",
        "\n",
        "image_output_path = \"/content/gdrive/MyDrive/Colab Notebooks/Prototype Code/Output/\"\n",
        "csv_output_path = image_output_path + \"/coral_areas_output.csv\"\n",
        "csv_columns = [\"Folder\", \"Image Name\", \"# Lesions\", \"Pixels Per um\", \"um^2\", \"Perimeters\"]\n",
        "\n",
        "areas_folder = os.path.join(image_output_path, \"areas\")\n",
        "perimeters_folder = os.path.join(image_output_path, \"perimeters\")\n",
        "os.makedirs(areas_folder, exist_ok=True)\n",
        "os.makedirs(perimeters_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7",
      "metadata": {
        "id": "1ea15c2e-9fac-428a-bc90-cd4f717efca7"
      },
      "source": [
        "## Run Measurer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f",
      "metadata": {
        "id": "8fb887b8-e08d-498a-9cc6-05e614205d5f"
      },
      "outputs": [],
      "source": [
        "pending_conversion = {}\n",
        "\n",
        "for index, folder in enumerate(image_input_path):\n",
        "    image_metadata_list = []\n",
        "    annotation_metadata_list = []\n",
        "    folder_name = os.path.basename(folder.rstrip('/'))\n",
        "    json_output_path = os.path.join(image_output_path, \"_annotations.coco.json\")\n",
        "    image_index = 0\n",
        "\n",
        "    for file in os.listdir(folder):\n",
        "        if file.endswith('.JPG'):\n",
        "            old_image_path = os.path.join(folder, file)\n",
        "            image_name, _ = os.path.splitext(file)\n",
        "            image_name_png = image_name + \".png\"\n",
        "            new_image_path = os.path.join(image_output_path, image_name_png)\n",
        "            image, height, width = open_image(old_image_path)\n",
        "\n",
        "            conversion_ratio = get_conversion_ratio(image, image_name)\n",
        "            if conversion_ratio is None:\n",
        "                pending_conversion[image_name] = (image, height, width, old_image_path)\n",
        "                continue\n",
        "\n",
        "            bboxes_lesion = run_yolo_lesion(image)\n",
        "            masks_lesion = run_sam(image, bboxes_lesion)\n",
        "            segmentations = masks_to_polygons(masks_lesion)\n",
        "            perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "            areas, centers = get_areas_and_centers(masks_lesion, bboxes_lesion, conversion_ratio)\n",
        "            id, date, repetition = image_info(image_name)\n",
        "\n",
        "            area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "            perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "            area_row = {'Date': date}\n",
        "            for i, a in enumerate(areas):\n",
        "                area_row[f'Area {i+1}'] = a\n",
        "            perim_row = {'Date': date}\n",
        "            for i, p in enumerate(perimeters):\n",
        "                perim_row[f'Perimeter {i+1}'] = p\n",
        "            append_row_to_excel(area_file, area_row)\n",
        "            append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "            output_image(image, height, width, new_image_path, bboxes_lesion, masks_lesion, segmentations, areas, centers)\n",
        "            output_csv(folder_name, image_name_png, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "            image_metadata, annotation_metadata = get_metadata(image_index, image_name_png, height, width, bboxes_lesion, segmentations)\n",
        "            image_metadata_list.append(image_metadata)\n",
        "            annotation_metadata_list.append(annotation_metadata)\n",
        "\n",
        "            image_index += 1\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    if image_metadata_list and annotation_metadata_list:\n",
        "        output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "\n",
        "resolved_ratios = {}\n",
        "\n",
        "pending_items = list(pending_conversion.items())\n",
        "current_idx = 0\n",
        "\n",
        "main_output = widgets.Output()\n",
        "display(main_output)\n",
        "\n",
        "image_metadata_list = []\n",
        "annotation_metadata_list = []\n",
        "json_output_path = os.path.join(image_output_path, \"_annotations.coco.json\")\n",
        "image_index = 0\n",
        "\n",
        "def process_next():\n",
        "    global current_idx\n",
        "    if current_idx >= len(pending_items):\n",
        "        with main_output:\n",
        "            clear_output()\n",
        "            print(\"All ratios collected. Now running analysis...\\n\")\n",
        "        run_analysis()\n",
        "        return\n",
        "\n",
        "    image_name, (image, height, width, old_image_path) = pending_items[current_idx]\n",
        "    current_idx += 1\n",
        "\n",
        "    def handle_ratio(ratio):\n",
        "        resolved_ratios[image_name] = ratio\n",
        "        process_next()\n",
        "\n",
        "    with main_output:\n",
        "        clear_output(wait=True)\n",
        "        ClickCollector(image, image_name, on_done=handle_ratio)\n",
        "\n",
        "def run_analysis():\n",
        "    for image_name, conversion_ratio in resolved_ratios.items():\n",
        "        if conversion_ratio is None:\n",
        "            print(f\"Skipping image {image_name} due to missing conversion ratio.\")\n",
        "            continue\n",
        "\n",
        "        image, height, width, old_image_path = pending_conversion[image_name]\n",
        "        image_name_png = image_name + \".png\"\n",
        "        new_image_path = os.path.join(image_output_path, image_name_png)\n",
        "\n",
        "        bboxes_lesion = run_yolo_lesion(image)\n",
        "        masks_lesion = run_sam(image, bboxes_lesion)\n",
        "        segmentations = masks_to_polygons(masks_lesion)\n",
        "        perimeters = get_perimeter(segmentations, conversion_ratio)\n",
        "        areas, centers = get_areas_and_centers(masks_lesion, bboxes_lesion, conversion_ratio)\n",
        "        id, date, repetition = image_info(image_name)\n",
        "\n",
        "        # Excel\n",
        "        area_file = os.path.join(areas_folder, f\"{id}_areas.xlsx\")\n",
        "        perim_file = os.path.join(perimeters_folder, f\"{id}_perimeters.xlsx\")\n",
        "        area_row = {'Date': date}\n",
        "        for i, a in enumerate(areas):\n",
        "            area_row[f'Area {i+1}'] = a\n",
        "        perim_row = {'Date': date}\n",
        "        for i, p in enumerate(perimeters):\n",
        "            perim_row[f'Perimeter {i+1}'] = p\n",
        "        append_row_to_excel(area_file, area_row)\n",
        "        append_row_to_excel(perim_file, perim_row)\n",
        "\n",
        "        # Output image + CSV\n",
        "        output_image(image, height, width, new_image_path, bboxes_lesion, masks_lesion, segmentations, areas, centers)\n",
        "        output_csv(\"manual_conversion\", image_name_png, len(masks_lesion), conversion_ratio, areas, perimeters, csv_output_path)\n",
        "\n",
        "        image_metadata, annotation_metadata = get_metadata(image_index, image_name_png, height, width, bboxes_lesion, segmentations)\n",
        "        image_metadata_list.append(image_metadata)\n",
        "        annotation_metadata_list.append(annotation_metadata)\n",
        "\n",
        "        image_index += 1\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if image_metadata_list and annotation_metadata_list:\n",
        "        output_coco_json(image_metadata_list, annotation_metadata_list, json_output_path)\n",
        "\n",
        "if pending_conversion:\n",
        "    process_next()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}